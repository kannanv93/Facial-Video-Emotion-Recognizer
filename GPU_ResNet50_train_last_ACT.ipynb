{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#from joblib import Parallel, delayed\n",
    "#from skimage.io import imread\n",
    "#from skimage.transform import resize\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import shutil, sys   \n",
    "#from google.colab.patches import cv2_imshow\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "#from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "#plt.ion()  \n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to fit hardware\n",
    "BATCH_SIZE = 64\n",
    "print_every = 50\n",
    "MODEL = 'alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/scratch/kv942/ccm_proj/datadir_act//'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "train_loader = DataLoader(image_datasets['train'],\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          )\n",
    "val_loader = DataLoader(image_datasets['val'],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         )\n",
    "# test_loader = DataLoader(image_datasets['test'],\n",
    "#                          batch_size=BATCH_SIZE,\n",
    "#                          shuffle=False,\n",
    "#                          )\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 39427, 'val': 4487}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "#imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    # Training steps\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        running_corrects = 0\n",
    "        number_training_steps = 0\n",
    "        # Iterate over data.\n",
    "        for batch_id, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
    "            outputs = model(inputs)\n",
    "            model.zero_grad() #same as optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() # sum up loss of all minibatches\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            number_training_steps+=1\n",
    "            \n",
    "            if batch_id % print_every == 0:\n",
    "                # report performance\n",
    "                print('Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_id * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_id / len(train_loader), loss.item()))\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_trainloss = running_loss / number_training_steps\n",
    "        #train_loss_list.append(epoch_trainloss)\n",
    "        epoch_trainaccuracy = running_corrects.double() / len(train_loader.dataset)\n",
    "        #train_acc_list.append(epoch_trainaccuracy)\n",
    "        \n",
    "        # report performance\n",
    "        print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch_trainloss, running_corrects, len(train_loader.dataset),\n",
    "        100. * epoch_trainaccuracy))\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Evaluate after every epoch\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            number_val_steps = 0\n",
    "            for batch_id, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                #print(\"labels = \", labels)\n",
    "                outputs = model(inputs)\n",
    "                #print(\"outputs = \", outputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() # sum up loss of all minibatches\n",
    "                number_val_steps += 1\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "                \n",
    "            \n",
    "            epoch_valloss = running_loss / number_val_steps\n",
    "            #val_loss_list.append(epoch_valloss)\n",
    "            epoch_valaccuracy = running_corrects.double() / len(val_loader.dataset)\n",
    "            #val_acc_list.append(epoch_valaccuracy)\n",
    "            #auc = roc_auc_score(truths, predictions)\n",
    "            \n",
    "            print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            epoch_valloss, running_corrects, len(val_loader.dataset),\n",
    "            100. * epoch_valaccuracy))\n",
    "    \n",
    "        # deep copy the model\n",
    "        if epoch_valaccuracy > best_acc:\n",
    "                best_acc = epoch_valaccuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/kv942/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c773a964c4c4b7eb30b6e41e310f8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"we have multiple GPUs..\")\n",
    "    model = nn.DataParallel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [64, 64, 112, 112]             128\n",
      "              ReLU-3         [64, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [64, 64, 56, 56]               0\n",
      "            Conv2d-5           [64, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [64, 64, 56, 56]             128\n",
      "              ReLU-7           [64, 64, 56, 56]               0\n",
      "            Conv2d-8           [64, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [64, 64, 56, 56]             128\n",
      "             ReLU-10           [64, 64, 56, 56]               0\n",
      "           Conv2d-11          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [64, 256, 56, 56]             512\n",
      "           Conv2d-13          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [64, 256, 56, 56]             512\n",
      "             ReLU-15          [64, 256, 56, 56]               0\n",
      "       Bottleneck-16          [64, 256, 56, 56]               0\n",
      "           Conv2d-17           [64, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [64, 64, 56, 56]             128\n",
      "             ReLU-19           [64, 64, 56, 56]               0\n",
      "           Conv2d-20           [64, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [64, 64, 56, 56]             128\n",
      "             ReLU-22           [64, 64, 56, 56]               0\n",
      "           Conv2d-23          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [64, 256, 56, 56]             512\n",
      "             ReLU-25          [64, 256, 56, 56]               0\n",
      "       Bottleneck-26          [64, 256, 56, 56]               0\n",
      "           Conv2d-27           [64, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [64, 64, 56, 56]             128\n",
      "             ReLU-29           [64, 64, 56, 56]               0\n",
      "           Conv2d-30           [64, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [64, 64, 56, 56]             128\n",
      "             ReLU-32           [64, 64, 56, 56]               0\n",
      "           Conv2d-33          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [64, 256, 56, 56]             512\n",
      "             ReLU-35          [64, 256, 56, 56]               0\n",
      "       Bottleneck-36          [64, 256, 56, 56]               0\n",
      "           Conv2d-37          [64, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [64, 128, 56, 56]             256\n",
      "             ReLU-39          [64, 128, 56, 56]               0\n",
      "           Conv2d-40          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [64, 128, 28, 28]             256\n",
      "             ReLU-42          [64, 128, 28, 28]               0\n",
      "           Conv2d-43          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [64, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [64, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [64, 512, 28, 28]           1,024\n",
      "             ReLU-47          [64, 512, 28, 28]               0\n",
      "       Bottleneck-48          [64, 512, 28, 28]               0\n",
      "           Conv2d-49          [64, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [64, 128, 28, 28]             256\n",
      "             ReLU-51          [64, 128, 28, 28]               0\n",
      "           Conv2d-52          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [64, 128, 28, 28]             256\n",
      "             ReLU-54          [64, 128, 28, 28]               0\n",
      "           Conv2d-55          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [64, 512, 28, 28]           1,024\n",
      "             ReLU-57          [64, 512, 28, 28]               0\n",
      "       Bottleneck-58          [64, 512, 28, 28]               0\n",
      "           Conv2d-59          [64, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [64, 128, 28, 28]             256\n",
      "             ReLU-61          [64, 128, 28, 28]               0\n",
      "           Conv2d-62          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [64, 128, 28, 28]             256\n",
      "             ReLU-64          [64, 128, 28, 28]               0\n",
      "           Conv2d-65          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [64, 512, 28, 28]           1,024\n",
      "             ReLU-67          [64, 512, 28, 28]               0\n",
      "       Bottleneck-68          [64, 512, 28, 28]               0\n",
      "           Conv2d-69          [64, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [64, 128, 28, 28]             256\n",
      "             ReLU-71          [64, 128, 28, 28]               0\n",
      "           Conv2d-72          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [64, 128, 28, 28]             256\n",
      "             ReLU-74          [64, 128, 28, 28]               0\n",
      "           Conv2d-75          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [64, 512, 28, 28]           1,024\n",
      "             ReLU-77          [64, 512, 28, 28]               0\n",
      "       Bottleneck-78          [64, 512, 28, 28]               0\n",
      "           Conv2d-79          [64, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [64, 256, 28, 28]             512\n",
      "             ReLU-81          [64, 256, 28, 28]               0\n",
      "           Conv2d-82          [64, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [64, 256, 14, 14]             512\n",
      "             ReLU-84          [64, 256, 14, 14]               0\n",
      "           Conv2d-85         [64, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [64, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [64, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [64, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [64, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [64, 1024, 14, 14]               0\n",
      "           Conv2d-91          [64, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [64, 256, 14, 14]             512\n",
      "             ReLU-93          [64, 256, 14, 14]               0\n",
      "           Conv2d-94          [64, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [64, 256, 14, 14]             512\n",
      "             ReLU-96          [64, 256, 14, 14]               0\n",
      "           Conv2d-97         [64, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [64, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [64, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [64, 1024, 14, 14]               0\n",
      "          Conv2d-101          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [64, 256, 14, 14]             512\n",
      "            ReLU-103          [64, 256, 14, 14]               0\n",
      "          Conv2d-104          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [64, 256, 14, 14]             512\n",
      "            ReLU-106          [64, 256, 14, 14]               0\n",
      "          Conv2d-107         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [64, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [64, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [64, 1024, 14, 14]               0\n",
      "          Conv2d-111          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [64, 256, 14, 14]             512\n",
      "            ReLU-113          [64, 256, 14, 14]               0\n",
      "          Conv2d-114          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [64, 256, 14, 14]             512\n",
      "            ReLU-116          [64, 256, 14, 14]               0\n",
      "          Conv2d-117         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [64, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [64, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [64, 1024, 14, 14]               0\n",
      "          Conv2d-121          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [64, 256, 14, 14]             512\n",
      "            ReLU-123          [64, 256, 14, 14]               0\n",
      "          Conv2d-124          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [64, 256, 14, 14]             512\n",
      "            ReLU-126          [64, 256, 14, 14]               0\n",
      "          Conv2d-127         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [64, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [64, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [64, 1024, 14, 14]               0\n",
      "          Conv2d-131          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [64, 256, 14, 14]             512\n",
      "            ReLU-133          [64, 256, 14, 14]               0\n",
      "          Conv2d-134          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [64, 256, 14, 14]             512\n",
      "            ReLU-136          [64, 256, 14, 14]               0\n",
      "          Conv2d-137         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [64, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [64, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [64, 1024, 14, 14]               0\n",
      "          Conv2d-141          [64, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [64, 512, 14, 14]           1,024\n",
      "            ReLU-143          [64, 512, 14, 14]               0\n",
      "          Conv2d-144            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [64, 512, 7, 7]           1,024\n",
      "            ReLU-146            [64, 512, 7, 7]               0\n",
      "          Conv2d-147           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [64, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [64, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [64, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [64, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [64, 2048, 7, 7]               0\n",
      "          Conv2d-153            [64, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [64, 512, 7, 7]           1,024\n",
      "            ReLU-155            [64, 512, 7, 7]               0\n",
      "          Conv2d-156            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [64, 512, 7, 7]           1,024\n",
      "            ReLU-158            [64, 512, 7, 7]               0\n",
      "          Conv2d-159           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [64, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [64, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [64, 2048, 7, 7]               0\n",
      "          Conv2d-163            [64, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [64, 512, 7, 7]           1,024\n",
      "            ReLU-165            [64, 512, 7, 7]               0\n",
      "          Conv2d-166            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [64, 512, 7, 7]           1,024\n",
      "            ReLU-168            [64, 512, 7, 7]               0\n",
      "          Conv2d-169           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [64, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [64, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [64, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [64, 2048, 1, 1]               0\n",
      "          Linear-174                    [64, 8]          16,392\n",
      "================================================================\n",
      "Total params: 23,524,424\n",
      "Trainable params: 16,392\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 36.75\n",
      "Forward/backward pass size (MB): 18339.25\n",
      "Params size (MB): 89.74\n",
      "Estimated Total Size (MB): 18465.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224), batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train [0/39427 (0%)]\tLoss: 2.149530\n",
      "Train [3200/39427 (8%)]\tLoss: 1.483621\n",
      "Train [6400/39427 (16%)]\tLoss: 1.621048\n",
      "Train [9600/39427 (24%)]\tLoss: 1.366948\n",
      "Train [12800/39427 (32%)]\tLoss: 1.470694\n",
      "Train [16000/39427 (41%)]\tLoss: 1.161606\n",
      "Train [19200/39427 (49%)]\tLoss: 1.177349\n",
      "Train [22400/39427 (57%)]\tLoss: 1.286365\n",
      "Train [25600/39427 (65%)]\tLoss: 1.205082\n",
      "Train [28800/39427 (73%)]\tLoss: 1.063229\n",
      "Train [32000/39427 (81%)]\tLoss: 1.167223\n",
      "Train [35200/39427 (89%)]\tLoss: 1.086544\n",
      "Train [38400/39427 (97%)]\tLoss: 1.063488\n",
      "Train set: Average loss: 1.3271, Accuracy: 20914/39427 (53.04%)\n",
      "Validation set: Average loss: 1.7221, Accuracy: 1779/4487 (39.65%)\n",
      "\n",
      "Epoch:  1\n",
      "Train [0/39427 (0%)]\tLoss: 1.143021\n",
      "Train [3200/39427 (8%)]\tLoss: 0.878929\n",
      "Train [6400/39427 (16%)]\tLoss: 1.042602\n",
      "Train [9600/39427 (24%)]\tLoss: 1.064815\n",
      "Train [12800/39427 (32%)]\tLoss: 1.292484\n",
      "Train [16000/39427 (41%)]\tLoss: 0.792833\n",
      "Train [19200/39427 (49%)]\tLoss: 1.152688\n",
      "Train [22400/39427 (57%)]\tLoss: 1.125247\n",
      "Train [25600/39427 (65%)]\tLoss: 0.998749\n",
      "Train [28800/39427 (73%)]\tLoss: 1.302595\n",
      "Train [32000/39427 (81%)]\tLoss: 1.304054\n",
      "Train [35200/39427 (89%)]\tLoss: 1.166984\n",
      "Train [38400/39427 (97%)]\tLoss: 0.946114\n",
      "Train set: Average loss: 1.0911, Accuracy: 24139/39427 (61.22%)\n",
      "Validation set: Average loss: 1.8235, Accuracy: 1561/4487 (34.79%)\n",
      "\n",
      "Epoch:  2\n",
      "Train [0/39427 (0%)]\tLoss: 1.083685\n",
      "Train [3200/39427 (8%)]\tLoss: 0.905738\n",
      "Train [6400/39427 (16%)]\tLoss: 0.949351\n",
      "Train [9600/39427 (24%)]\tLoss: 1.169970\n",
      "Train [12800/39427 (32%)]\tLoss: 0.934748\n",
      "Train [16000/39427 (41%)]\tLoss: 0.889543\n",
      "Train [19200/39427 (49%)]\tLoss: 0.831953\n",
      "Train [22400/39427 (57%)]\tLoss: 1.136771\n",
      "Train [25600/39427 (65%)]\tLoss: 0.818720\n",
      "Train [28800/39427 (73%)]\tLoss: 0.890542\n",
      "Train [32000/39427 (81%)]\tLoss: 0.900185\n",
      "Train [35200/39427 (89%)]\tLoss: 1.153499\n",
      "Train [38400/39427 (97%)]\tLoss: 0.892767\n",
      "Train set: Average loss: 1.0238, Accuracy: 25096/39427 (63.65%)\n",
      "Validation set: Average loss: 1.7279, Accuracy: 1909/4487 (42.55%)\n",
      "\n",
      "Epoch:  3\n",
      "Train [0/39427 (0%)]\tLoss: 0.709433\n",
      "Train [3200/39427 (8%)]\tLoss: 0.992777\n",
      "Train [6400/39427 (16%)]\tLoss: 0.801720\n",
      "Train [9600/39427 (24%)]\tLoss: 0.968319\n",
      "Train [12800/39427 (32%)]\tLoss: 1.045606\n",
      "Train [16000/39427 (41%)]\tLoss: 1.099256\n",
      "Train [19200/39427 (49%)]\tLoss: 0.785856\n",
      "Train [22400/39427 (57%)]\tLoss: 1.319192\n",
      "Train [25600/39427 (65%)]\tLoss: 0.861682\n",
      "Train [28800/39427 (73%)]\tLoss: 0.840097\n",
      "Train [32000/39427 (81%)]\tLoss: 0.812714\n",
      "Train [35200/39427 (89%)]\tLoss: 0.990218\n",
      "Train [38400/39427 (97%)]\tLoss: 0.937406\n",
      "Train set: Average loss: 0.9767, Accuracy: 25710/39427 (65.21%)\n",
      "Validation set: Average loss: 1.8165, Accuracy: 1707/4487 (38.04%)\n",
      "\n",
      "Epoch:  4\n",
      "Train [0/39427 (0%)]\tLoss: 1.016951\n",
      "Train [3200/39427 (8%)]\tLoss: 0.848811\n",
      "Train [6400/39427 (16%)]\tLoss: 0.867347\n",
      "Train [9600/39427 (24%)]\tLoss: 1.108183\n",
      "Train [12800/39427 (32%)]\tLoss: 1.106153\n",
      "Train [16000/39427 (41%)]\tLoss: 0.890185\n",
      "Train [19200/39427 (49%)]\tLoss: 1.186439\n",
      "Train [22400/39427 (57%)]\tLoss: 0.823651\n",
      "Train [25600/39427 (65%)]\tLoss: 0.949932\n",
      "Train [28800/39427 (73%)]\tLoss: 0.821493\n",
      "Train [32000/39427 (81%)]\tLoss: 0.879866\n",
      "Train [35200/39427 (89%)]\tLoss: 1.065419\n",
      "Train [38400/39427 (97%)]\tLoss: 1.011641\n",
      "Train set: Average loss: 0.9447, Accuracy: 26086/39427 (66.16%)\n",
      "Validation set: Average loss: 1.7735, Accuracy: 1746/4487 (38.91%)\n",
      "\n",
      "Training complete in 96m 13s\n",
      "Best val Acc: 0.425451\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_results/AlexNet_train_lastlayer_ACT.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
