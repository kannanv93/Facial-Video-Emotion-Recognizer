{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#from joblib import Parallel, delayed\n",
    "#from skimage.io import imread\n",
    "#from skimage.transform import resize\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import shutil, sys   \n",
    "#from google.colab.patches import cv2_imshow\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "#from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "#plt.ion()  \n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to fit hardware\n",
    "BATCH_SIZE = 64\n",
    "print_every = 50\n",
    "MODEL = 'alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/scratch/kv942/ccm_proj/datadir_act//'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "train_loader = DataLoader(image_datasets['train'],\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          )\n",
    "val_loader = DataLoader(image_datasets['val'],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         )\n",
    "# test_loader = DataLoader(image_datasets['test'],\n",
    "#                          batch_size=BATCH_SIZE,\n",
    "#                          shuffle=False,\n",
    "#                          )\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 39427, 'val': 4487}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "#imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    # Training steps\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.529530\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        running_corrects = 0\n",
    "        number_training_steps = 0\n",
    "        # Iterate over data.\n",
    "        for batch_id, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
    "            outputs = model(inputs)\n",
    "            model.zero_grad() #same as optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() # sum up loss of all minibatches\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            number_training_steps+=1\n",
    "            \n",
    "            if batch_id % print_every == 0:\n",
    "                # report performance\n",
    "                print('Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_id * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_id / len(train_loader), loss.item()))\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_trainloss = running_loss / number_training_steps\n",
    "        #train_loss_list.append(epoch_trainloss)\n",
    "        epoch_trainaccuracy = running_corrects.double() / len(train_loader.dataset)\n",
    "        #train_acc_list.append(epoch_trainaccuracy)\n",
    "        \n",
    "        # report performance\n",
    "        print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch_trainloss, running_corrects, len(train_loader.dataset),\n",
    "        100. * epoch_trainaccuracy))\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Evaluate after every epoch\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            number_val_steps = 0\n",
    "            for batch_id, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                #print(\"labels = \", labels)\n",
    "                outputs = model(inputs)\n",
    "                #print(\"outputs = \", outputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() # sum up loss of all minibatches\n",
    "                number_val_steps += 1\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "                \n",
    "            \n",
    "            epoch_valloss = running_loss / number_val_steps\n",
    "            #val_loss_list.append(epoch_valloss)\n",
    "            epoch_valaccuracy = running_corrects.double() / len(val_loader.dataset)\n",
    "            #val_acc_list.append(epoch_valaccuracy)\n",
    "            #auc = roc_auc_score(truths, predictions)\n",
    "            \n",
    "            print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            epoch_valloss, running_corrects, len(val_loader.dataset),\n",
    "            100. * epoch_valaccuracy))\n",
    "    \n",
    "        # deep copy the model\n",
    "        if epoch_valaccuracy > best_acc:\n",
    "                best_acc = epoch_valaccuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['senet154'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnet50()\n",
    "model.last_linear = nn.Linear(in_features=2048, out_features=8, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SENet(\n",
       "  (layer0): Sequential(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (5): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNetBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (last_linear): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"we have multiple GPUs..\")\n",
    "    model = nn.DataParallel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [64, 64, 112, 112]             128\n",
      "              ReLU-3         [64, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [64, 64, 56, 56]               0\n",
      "            Conv2d-5           [64, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [64, 64, 56, 56]             128\n",
      "              ReLU-7           [64, 64, 56, 56]               0\n",
      "            Conv2d-8           [64, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [64, 64, 56, 56]             128\n",
      "             ReLU-10           [64, 64, 56, 56]               0\n",
      "           Conv2d-11          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [64, 256, 56, 56]             512\n",
      "           Conv2d-13          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [64, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-15            [64, 256, 1, 1]               0\n",
      "           Conv2d-16             [64, 16, 1, 1]           4,112\n",
      "             ReLU-17             [64, 16, 1, 1]               0\n",
      "           Conv2d-18            [64, 256, 1, 1]           4,352\n",
      "          Sigmoid-19            [64, 256, 1, 1]               0\n",
      "         SEModule-20          [64, 256, 56, 56]               0\n",
      "             ReLU-21          [64, 256, 56, 56]               0\n",
      "SEResNetBottleneck-22          [64, 256, 56, 56]               0\n",
      "           Conv2d-23           [64, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-24           [64, 64, 56, 56]             128\n",
      "             ReLU-25           [64, 64, 56, 56]               0\n",
      "           Conv2d-26           [64, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-27           [64, 64, 56, 56]             128\n",
      "             ReLU-28           [64, 64, 56, 56]               0\n",
      "           Conv2d-29          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-30          [64, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-31            [64, 256, 1, 1]               0\n",
      "           Conv2d-32             [64, 16, 1, 1]           4,112\n",
      "             ReLU-33             [64, 16, 1, 1]               0\n",
      "           Conv2d-34            [64, 256, 1, 1]           4,352\n",
      "          Sigmoid-35            [64, 256, 1, 1]               0\n",
      "         SEModule-36          [64, 256, 56, 56]               0\n",
      "             ReLU-37          [64, 256, 56, 56]               0\n",
      "SEResNetBottleneck-38          [64, 256, 56, 56]               0\n",
      "           Conv2d-39           [64, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-40           [64, 64, 56, 56]             128\n",
      "             ReLU-41           [64, 64, 56, 56]               0\n",
      "           Conv2d-42           [64, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-43           [64, 64, 56, 56]             128\n",
      "             ReLU-44           [64, 64, 56, 56]               0\n",
      "           Conv2d-45          [64, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-46          [64, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-47            [64, 256, 1, 1]               0\n",
      "           Conv2d-48             [64, 16, 1, 1]           4,112\n",
      "             ReLU-49             [64, 16, 1, 1]               0\n",
      "           Conv2d-50            [64, 256, 1, 1]           4,352\n",
      "          Sigmoid-51            [64, 256, 1, 1]               0\n",
      "         SEModule-52          [64, 256, 56, 56]               0\n",
      "             ReLU-53          [64, 256, 56, 56]               0\n",
      "SEResNetBottleneck-54          [64, 256, 56, 56]               0\n",
      "           Conv2d-55          [64, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-56          [64, 128, 28, 28]             256\n",
      "             ReLU-57          [64, 128, 28, 28]               0\n",
      "           Conv2d-58          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-59          [64, 128, 28, 28]             256\n",
      "             ReLU-60          [64, 128, 28, 28]               0\n",
      "           Conv2d-61          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-62          [64, 512, 28, 28]           1,024\n",
      "           Conv2d-63          [64, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-64          [64, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-65            [64, 512, 1, 1]               0\n",
      "           Conv2d-66             [64, 32, 1, 1]          16,416\n",
      "             ReLU-67             [64, 32, 1, 1]               0\n",
      "           Conv2d-68            [64, 512, 1, 1]          16,896\n",
      "          Sigmoid-69            [64, 512, 1, 1]               0\n",
      "         SEModule-70          [64, 512, 28, 28]               0\n",
      "             ReLU-71          [64, 512, 28, 28]               0\n",
      "SEResNetBottleneck-72          [64, 512, 28, 28]               0\n",
      "           Conv2d-73          [64, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-74          [64, 128, 28, 28]             256\n",
      "             ReLU-75          [64, 128, 28, 28]               0\n",
      "           Conv2d-76          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-77          [64, 128, 28, 28]             256\n",
      "             ReLU-78          [64, 128, 28, 28]               0\n",
      "           Conv2d-79          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [64, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-81            [64, 512, 1, 1]               0\n",
      "           Conv2d-82             [64, 32, 1, 1]          16,416\n",
      "             ReLU-83             [64, 32, 1, 1]               0\n",
      "           Conv2d-84            [64, 512, 1, 1]          16,896\n",
      "          Sigmoid-85            [64, 512, 1, 1]               0\n",
      "         SEModule-86          [64, 512, 28, 28]               0\n",
      "             ReLU-87          [64, 512, 28, 28]               0\n",
      "SEResNetBottleneck-88          [64, 512, 28, 28]               0\n",
      "           Conv2d-89          [64, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [64, 128, 28, 28]             256\n",
      "             ReLU-91          [64, 128, 28, 28]               0\n",
      "           Conv2d-92          [64, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [64, 128, 28, 28]             256\n",
      "             ReLU-94          [64, 128, 28, 28]               0\n",
      "           Conv2d-95          [64, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [64, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-97            [64, 512, 1, 1]               0\n",
      "           Conv2d-98             [64, 32, 1, 1]          16,416\n",
      "             ReLU-99             [64, 32, 1, 1]               0\n",
      "          Conv2d-100            [64, 512, 1, 1]          16,896\n",
      "         Sigmoid-101            [64, 512, 1, 1]               0\n",
      "        SEModule-102          [64, 512, 28, 28]               0\n",
      "            ReLU-103          [64, 512, 28, 28]               0\n",
      "SEResNetBottleneck-104          [64, 512, 28, 28]               0\n",
      "          Conv2d-105          [64, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [64, 128, 28, 28]             256\n",
      "            ReLU-107          [64, 128, 28, 28]               0\n",
      "          Conv2d-108          [64, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-109          [64, 128, 28, 28]             256\n",
      "            ReLU-110          [64, 128, 28, 28]               0\n",
      "          Conv2d-111          [64, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-112          [64, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-113            [64, 512, 1, 1]               0\n",
      "          Conv2d-114             [64, 32, 1, 1]          16,416\n",
      "            ReLU-115             [64, 32, 1, 1]               0\n",
      "          Conv2d-116            [64, 512, 1, 1]          16,896\n",
      "         Sigmoid-117            [64, 512, 1, 1]               0\n",
      "        SEModule-118          [64, 512, 28, 28]               0\n",
      "            ReLU-119          [64, 512, 28, 28]               0\n",
      "SEResNetBottleneck-120          [64, 512, 28, 28]               0\n",
      "          Conv2d-121          [64, 256, 14, 14]         131,072\n",
      "     BatchNorm2d-122          [64, 256, 14, 14]             512\n",
      "            ReLU-123          [64, 256, 14, 14]               0\n",
      "          Conv2d-124          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [64, 256, 14, 14]             512\n",
      "            ReLU-126          [64, 256, 14, 14]               0\n",
      "          Conv2d-127         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [64, 1024, 14, 14]           2,048\n",
      "          Conv2d-129         [64, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-130         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-131           [64, 1024, 1, 1]               0\n",
      "          Conv2d-132             [64, 64, 1, 1]          65,600\n",
      "            ReLU-133             [64, 64, 1, 1]               0\n",
      "          Conv2d-134           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-135           [64, 1024, 1, 1]               0\n",
      "        SEModule-136         [64, 1024, 14, 14]               0\n",
      "            ReLU-137         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-138         [64, 1024, 14, 14]               0\n",
      "          Conv2d-139          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-140          [64, 256, 14, 14]             512\n",
      "            ReLU-141          [64, 256, 14, 14]               0\n",
      "          Conv2d-142          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-143          [64, 256, 14, 14]             512\n",
      "            ReLU-144          [64, 256, 14, 14]               0\n",
      "          Conv2d-145         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-146         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-147           [64, 1024, 1, 1]               0\n",
      "          Conv2d-148             [64, 64, 1, 1]          65,600\n",
      "            ReLU-149             [64, 64, 1, 1]               0\n",
      "          Conv2d-150           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-151           [64, 1024, 1, 1]               0\n",
      "        SEModule-152         [64, 1024, 14, 14]               0\n",
      "            ReLU-153         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-154         [64, 1024, 14, 14]               0\n",
      "          Conv2d-155          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-156          [64, 256, 14, 14]             512\n",
      "            ReLU-157          [64, 256, 14, 14]               0\n",
      "          Conv2d-158          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-159          [64, 256, 14, 14]             512\n",
      "            ReLU-160          [64, 256, 14, 14]               0\n",
      "          Conv2d-161         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-162         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-163           [64, 1024, 1, 1]               0\n",
      "          Conv2d-164             [64, 64, 1, 1]          65,600\n",
      "            ReLU-165             [64, 64, 1, 1]               0\n",
      "          Conv2d-166           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-167           [64, 1024, 1, 1]               0\n",
      "        SEModule-168         [64, 1024, 14, 14]               0\n",
      "            ReLU-169         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-170         [64, 1024, 14, 14]               0\n",
      "          Conv2d-171          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [64, 256, 14, 14]             512\n",
      "            ReLU-173          [64, 256, 14, 14]               0\n",
      "          Conv2d-174          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [64, 256, 14, 14]             512\n",
      "            ReLU-176          [64, 256, 14, 14]               0\n",
      "          Conv2d-177         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-179           [64, 1024, 1, 1]               0\n",
      "          Conv2d-180             [64, 64, 1, 1]          65,600\n",
      "            ReLU-181             [64, 64, 1, 1]               0\n",
      "          Conv2d-182           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-183           [64, 1024, 1, 1]               0\n",
      "        SEModule-184         [64, 1024, 14, 14]               0\n",
      "            ReLU-185         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-186         [64, 1024, 14, 14]               0\n",
      "          Conv2d-187          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-188          [64, 256, 14, 14]             512\n",
      "            ReLU-189          [64, 256, 14, 14]               0\n",
      "          Conv2d-190          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-191          [64, 256, 14, 14]             512\n",
      "            ReLU-192          [64, 256, 14, 14]               0\n",
      "          Conv2d-193         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-194         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-195           [64, 1024, 1, 1]               0\n",
      "          Conv2d-196             [64, 64, 1, 1]          65,600\n",
      "            ReLU-197             [64, 64, 1, 1]               0\n",
      "          Conv2d-198           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-199           [64, 1024, 1, 1]               0\n",
      "        SEModule-200         [64, 1024, 14, 14]               0\n",
      "            ReLU-201         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-202         [64, 1024, 14, 14]               0\n",
      "          Conv2d-203          [64, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-204          [64, 256, 14, 14]             512\n",
      "            ReLU-205          [64, 256, 14, 14]               0\n",
      "          Conv2d-206          [64, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-207          [64, 256, 14, 14]             512\n",
      "            ReLU-208          [64, 256, 14, 14]               0\n",
      "          Conv2d-209         [64, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-210         [64, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-211           [64, 1024, 1, 1]               0\n",
      "          Conv2d-212             [64, 64, 1, 1]          65,600\n",
      "            ReLU-213             [64, 64, 1, 1]               0\n",
      "          Conv2d-214           [64, 1024, 1, 1]          66,560\n",
      "         Sigmoid-215           [64, 1024, 1, 1]               0\n",
      "        SEModule-216         [64, 1024, 14, 14]               0\n",
      "            ReLU-217         [64, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-218         [64, 1024, 14, 14]               0\n",
      "          Conv2d-219            [64, 512, 7, 7]         524,288\n",
      "     BatchNorm2d-220            [64, 512, 7, 7]           1,024\n",
      "            ReLU-221            [64, 512, 7, 7]               0\n",
      "          Conv2d-222            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-223            [64, 512, 7, 7]           1,024\n",
      "            ReLU-224            [64, 512, 7, 7]               0\n",
      "          Conv2d-225           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-226           [64, 2048, 7, 7]           4,096\n",
      "          Conv2d-227           [64, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-228           [64, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-229           [64, 2048, 1, 1]               0\n",
      "          Conv2d-230            [64, 128, 1, 1]         262,272\n",
      "            ReLU-231            [64, 128, 1, 1]               0\n",
      "          Conv2d-232           [64, 2048, 1, 1]         264,192\n",
      "         Sigmoid-233           [64, 2048, 1, 1]               0\n",
      "        SEModule-234           [64, 2048, 7, 7]               0\n",
      "            ReLU-235           [64, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-236           [64, 2048, 7, 7]               0\n",
      "          Conv2d-237            [64, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-238            [64, 512, 7, 7]           1,024\n",
      "            ReLU-239            [64, 512, 7, 7]               0\n",
      "          Conv2d-240            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-241            [64, 512, 7, 7]           1,024\n",
      "            ReLU-242            [64, 512, 7, 7]               0\n",
      "          Conv2d-243           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-244           [64, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-245           [64, 2048, 1, 1]               0\n",
      "          Conv2d-246            [64, 128, 1, 1]         262,272\n",
      "            ReLU-247            [64, 128, 1, 1]               0\n",
      "          Conv2d-248           [64, 2048, 1, 1]         264,192\n",
      "         Sigmoid-249           [64, 2048, 1, 1]               0\n",
      "        SEModule-250           [64, 2048, 7, 7]               0\n",
      "            ReLU-251           [64, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-252           [64, 2048, 7, 7]               0\n",
      "          Conv2d-253            [64, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-254            [64, 512, 7, 7]           1,024\n",
      "            ReLU-255            [64, 512, 7, 7]               0\n",
      "          Conv2d-256            [64, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-257            [64, 512, 7, 7]           1,024\n",
      "            ReLU-258            [64, 512, 7, 7]               0\n",
      "          Conv2d-259           [64, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-260           [64, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-261           [64, 2048, 1, 1]               0\n",
      "          Conv2d-262            [64, 128, 1, 1]         262,272\n",
      "            ReLU-263            [64, 128, 1, 1]               0\n",
      "          Conv2d-264           [64, 2048, 1, 1]         264,192\n",
      "         Sigmoid-265           [64, 2048, 1, 1]               0\n",
      "        SEModule-266           [64, 2048, 7, 7]               0\n",
      "            ReLU-267           [64, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-268           [64, 2048, 7, 7]               0\n",
      "       AvgPool2d-269           [64, 2048, 1, 1]               0\n",
      "          Linear-270                    [64, 8]          16,392\n",
      "================================================================\n",
      "Total params: 26,055,416\n",
      "Trainable params: 26,055,416\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 36.75\n",
      "Forward/backward pass size (MB): 20285.55\n",
      "Params size (MB): 99.39\n",
      "Estimated Total Size (MB): 20421.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224), batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train [0/39427 (0%)]\tLoss: 2.083137\n",
      "Train [3200/39427 (8%)]\tLoss: 0.645747\n",
      "Train [6400/39427 (16%)]\tLoss: 0.614793\n",
      "Train [9600/39427 (24%)]\tLoss: 0.481973\n",
      "Train [12800/39427 (32%)]\tLoss: 0.414444\n",
      "Train [16000/39427 (41%)]\tLoss: 0.373637\n",
      "Train [19200/39427 (49%)]\tLoss: 0.491742\n",
      "Train [22400/39427 (57%)]\tLoss: 0.436822\n",
      "Train [25600/39427 (65%)]\tLoss: 0.440731\n",
      "Train [28800/39427 (73%)]\tLoss: 0.350176\n",
      "Train [32000/39427 (81%)]\tLoss: 0.559731\n",
      "Train [35200/39427 (89%)]\tLoss: 0.341264\n",
      "Train [38400/39427 (97%)]\tLoss: 0.386188\n",
      "Train set: Average loss: 0.4963, Accuracy: 32534/39427 (82.52%)\n",
      "Validation set: Average loss: 2.7443, Accuracy: 1767/4487 (39.38%)\n",
      "\n",
      "Epoch:  1\n",
      "Train [0/39427 (0%)]\tLoss: 0.290121\n",
      "Train [3200/39427 (8%)]\tLoss: 0.361448\n",
      "Train [6400/39427 (16%)]\tLoss: 0.305460\n",
      "Train [9600/39427 (24%)]\tLoss: 0.150177\n",
      "Train [12800/39427 (32%)]\tLoss: 0.108315\n",
      "Train [16000/39427 (41%)]\tLoss: 0.152165\n",
      "Train [19200/39427 (49%)]\tLoss: 0.218006\n",
      "Train [22400/39427 (57%)]\tLoss: 0.087224\n",
      "Train [25600/39427 (65%)]\tLoss: 0.187099\n",
      "Train [28800/39427 (73%)]\tLoss: 0.217937\n",
      "Train [32000/39427 (81%)]\tLoss: 0.175440\n",
      "Train [35200/39427 (89%)]\tLoss: 0.152386\n",
      "Train [38400/39427 (97%)]\tLoss: 0.166991\n",
      "Train set: Average loss: 0.2303, Accuracy: 36343/39427 (92.18%)\n",
      "Validation set: Average loss: 2.2399, Accuracy: 2209/4487 (49.23%)\n",
      "\n",
      "Epoch:  2\n",
      "Train [0/39427 (0%)]\tLoss: 0.170927\n",
      "Train [3200/39427 (8%)]\tLoss: 0.282729\n",
      "Train [6400/39427 (16%)]\tLoss: 0.156241\n",
      "Train [9600/39427 (24%)]\tLoss: 0.161316\n",
      "Train [12800/39427 (32%)]\tLoss: 0.131076\n",
      "Train [16000/39427 (41%)]\tLoss: 0.054354\n",
      "Train [19200/39427 (49%)]\tLoss: 0.118914\n",
      "Train [22400/39427 (57%)]\tLoss: 0.145376\n",
      "Train [25600/39427 (65%)]\tLoss: 0.117180\n",
      "Train [28800/39427 (73%)]\tLoss: 0.206774\n",
      "Train [32000/39427 (81%)]\tLoss: 0.084537\n",
      "Train [35200/39427 (89%)]\tLoss: 0.146477\n",
      "Train [38400/39427 (97%)]\tLoss: 0.046317\n",
      "Train set: Average loss: 0.1446, Accuracy: 37473/39427 (95.04%)\n",
      "Validation set: Average loss: 2.1146, Accuracy: 2376/4487 (52.95%)\n",
      "\n",
      "Training complete in 84m 6s\n",
      "Best val Acc: 0.529530\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train [0/39427 (0%)]\tLoss: 0.075305\n",
      "Train [3200/39427 (8%)]\tLoss: 0.264581\n",
      "Train [6400/39427 (16%)]\tLoss: 0.081573\n",
      "Train [9600/39427 (24%)]\tLoss: 0.084451\n",
      "Train [12800/39427 (32%)]\tLoss: 0.062008\n",
      "Train [16000/39427 (41%)]\tLoss: 0.067236\n",
      "Train [19200/39427 (49%)]\tLoss: 0.030752\n",
      "Train [22400/39427 (57%)]\tLoss: 0.031098\n",
      "Train [25600/39427 (65%)]\tLoss: 0.050557\n",
      "Train [28800/39427 (73%)]\tLoss: 0.049706\n",
      "Train [32000/39427 (81%)]\tLoss: 0.045391\n",
      "Train [35200/39427 (89%)]\tLoss: 0.137065\n",
      "Train [38400/39427 (97%)]\tLoss: 0.054768\n",
      "Train set: Average loss: 0.1119, Accuracy: 37938/39427 (96.22%)\n",
      "Validation set: Average loss: 2.0805, Accuracy: 2307/4487 (51.42%)\n",
      "\n",
      "Epoch:  1\n",
      "Train [0/39427 (0%)]\tLoss: 0.064279\n",
      "Train [3200/39427 (8%)]\tLoss: 0.065747\n",
      "Train [6400/39427 (16%)]\tLoss: 0.063099\n",
      "Train [9600/39427 (24%)]\tLoss: 0.108607\n",
      "Train [12800/39427 (32%)]\tLoss: 0.057268\n",
      "Train [16000/39427 (41%)]\tLoss: 0.146918\n",
      "Train [19200/39427 (49%)]\tLoss: 0.031863\n",
      "Train [22400/39427 (57%)]\tLoss: 0.090274\n",
      "Train [25600/39427 (65%)]\tLoss: 0.035493\n",
      "Train [28800/39427 (73%)]\tLoss: 0.044881\n",
      "Train [32000/39427 (81%)]\tLoss: 0.237814\n",
      "Train [35200/39427 (89%)]\tLoss: 0.049256\n",
      "Train [38400/39427 (97%)]\tLoss: 0.093387\n",
      "Train set: Average loss: 0.0787, Accuracy: 38424/39427 (97.46%)\n",
      "Validation set: Average loss: 2.9706, Accuracy: 1927/4487 (42.95%)\n",
      "\n",
      "Training complete in 54m 17s\n",
      "Best val Acc: 0.529530\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization & Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "def test_performance(model):\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        number_test_steps = 0\n",
    "        for batch_id, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "            #print(\"labels = \", labels)\n",
    "            outputs = model(inputs)\n",
    "            #print(\"outputs = \", outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() # sum up loss of all minibatches\n",
    "            number_test_steps += 1\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "\n",
    "\n",
    "        epoch_testloss = running_loss / number_test_steps\n",
    "        #val_loss_list.append(epoch_valloss)\n",
    "        epoch_testaccuracy = running_corrects.double() / len(test_loader.dataset)\n",
    "        #val_acc_list.append(epoch_valaccuracy)\n",
    "        #auc = roc_auc_score(truths, predictions)\n",
    "\n",
    "        print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        epoch_testloss, running_corrects, len(test_loader.dataset),\n",
    "        100. * epoch_testaccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_results/SE_RESNET50_ACT_1.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
