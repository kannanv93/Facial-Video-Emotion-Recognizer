{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Qvd9gY4Cley"
   },
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#from joblib import Parallel, delayed\n",
    "#from skimage.io import imread\n",
    "#from skimage.transform import resize\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyXHQ9lWTg9n"
   },
   "outputs": [],
   "source": [
    "import shutil, sys   \n",
    "#from google.colab.patches import cv2_imshow\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "#from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "#plt.ion()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCIlSzPPe3dZ"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoFPytsUlrJ5"
   },
   "outputs": [],
   "source": [
    "# traindir = \"datadir/train/\"\n",
    "# valdir = \"datadir/val/\"\n",
    "# testdir = \"datadir/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fanGV_7BLFnW"
   },
   "outputs": [],
   "source": [
    "# Change to fit hardware\n",
    "BATCH_SIZE = 64\n",
    "print_every = 50\n",
    "MODEL = 'alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnJ6CI0-4Vgg"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/scratch/sg5783/CCM_Project/datadir-new'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "train_loader = DataLoader(image_datasets['train'],\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          )\n",
    "val_loader = DataLoader(image_datasets['val'],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         )\n",
    "# test_loader = DataLoader(image_datasets['test'],\n",
    "#                          batch_size=BATCH_SIZE,\n",
    "#                          shuffle=False,\n",
    "#                          )\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pEviPoEWcLcm",
    "outputId": "466dc3af-b3b9-4d4e-b539-d09691fb0bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 14674, 'val': 1756}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZKGFcXTVs4W"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLR3LpURXl5N"
   },
   "outputs": [],
   "source": [
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "#imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3k55TCk9azJ-"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRYrfPkSXuKw"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    # Training steps\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        for batch_id, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
    "            outputs = model(inputs)\n",
    "            model.zero_grad() #same as optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() # sum up loss of all minibatches\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_id % print_every == 0:\n",
    "                # report performance\n",
    "                print('Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_id * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_id / len(train_loader), loss.item()))\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_trainloss = running_loss / len(train_loader.dataset)\n",
    "        #train_loss_list.append(epoch_trainloss)\n",
    "        epoch_trainaccuracy = running_corrects.double() / len(train_loader.dataset)\n",
    "        #train_acc_list.append(epoch_trainaccuracy)\n",
    "        \n",
    "        # report performance\n",
    "        print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch_trainloss, running_corrects, len(train_loader.dataset),\n",
    "        100. * epoch_trainaccuracy))\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Evaluate after every epoch\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_id, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                #print(\"labels = \", labels)\n",
    "                outputs = model(inputs)\n",
    "                #print(\"outputs = \", outputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() # sum up loss of all minibatches\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "                \n",
    "            \n",
    "            epoch_valloss = running_loss / len(val_loader.dataset)\n",
    "            #val_loss_list.append(epoch_valloss)\n",
    "            epoch_valaccuracy = running_corrects.double() / len(val_loader.dataset)\n",
    "            #val_acc_list.append(epoch_valaccuracy)\n",
    "            #auc = roc_auc_score(truths, predictions)\n",
    "            \n",
    "            print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            epoch_valloss, running_corrects, len(val_loader.dataset),\n",
    "            100. * epoch_valaccuracy))\n",
    "    \n",
    "        # deep copy the model\n",
    "        if epoch_valaccuracy > best_acc:\n",
    "                best_acc = epoch_valaccuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EszPsCY0XxtR"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "e36d104d3a824f9d99f5a134023ed3f6",
      "681fbb38dd104a99905eac8b7e830fc1",
      "8478c3442abc45188fc1b1bfcb7439b0",
      "4ca2f791e113495ca6cdc8a87fe092e5",
      "56089c3b980b47688145e2686dd0cd58",
      "49b4d1f0906e417e864aea18226dfea1",
      "987920b37ee94570a655dc244f53544f",
      "d3b6000d24854c2d8d86e597c58e9e64"
     ]
    },
    "colab_type": "code",
    "id": "FwoT7413YYTF",
    "outputId": "bd6f6664-b1f1-4929-9aac-6766a7a5200e"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "##changing the number of classes and adding batchnorm layers\n",
    "# model.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             #nn.Dropout(p=0.1),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "#             #nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             #nn.Dropout(p=0.1),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "#             #nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "#             #nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             #nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, len(class_names)),\n",
    "        )\n",
    "#model.classifier[6] = nn.Linear(4096, len(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_state_dict = torchvision.models.alexnet(pretrained=True).state_dict()\n",
    "# pretrained_param_names = list(pretrained_state_dict.keys())\n",
    "\n",
    "# for i, param in enumerate(pretrained_param_names[:-2]): \n",
    "#     print(\"\\n\", param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NngN_zGtYsRO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = features.0.weight param = Parameter containing:\n",
      "tensor([[[[ 1.1864e-01,  9.4069e-02,  9.5435e-02,  ...,  5.5822e-02,\n",
      "            2.1575e-02,  4.9963e-02],\n",
      "          [ 7.4882e-02,  3.8940e-02,  5.2979e-02,  ...,  2.5709e-02,\n",
      "           -1.1299e-02,  4.1590e-03],\n",
      "          [ 7.5425e-02,  3.8779e-02,  5.4930e-02,  ...,  4.3596e-02,\n",
      "            1.0225e-02,  1.3251e-02],\n",
      "          ...,\n",
      "          [ 9.3155e-02,  1.0374e-01,  6.7547e-02,  ..., -2.0277e-01,\n",
      "           -1.2839e-01, -1.1220e-01],\n",
      "          [ 4.3544e-02,  6.4916e-02,  3.6164e-02,  ..., -2.0248e-01,\n",
      "           -1.1376e-01, -1.0719e-01],\n",
      "          [ 4.7369e-02,  6.2543e-02,  2.4758e-02,  ..., -1.1844e-01,\n",
      "           -9.5567e-02, -8.3890e-02]],\n",
      "\n",
      "         [[-7.2634e-02, -5.7996e-02, -8.0661e-02,  ..., -6.0304e-04,\n",
      "           -2.5309e-02,  2.5471e-02],\n",
      "          [-6.9042e-02, -6.7562e-02, -7.6367e-02,  ..., -3.9616e-03,\n",
      "           -3.0402e-02,  1.0477e-02],\n",
      "          [-9.9517e-02, -8.5592e-02, -1.0521e-01,  ..., -2.6587e-02,\n",
      "           -2.2777e-02,  6.6451e-03],\n",
      "          ...,\n",
      "          [-1.5121e-01, -8.8735e-02, -9.6737e-02,  ...,  3.0853e-01,\n",
      "            1.8096e-01,  8.4297e-02],\n",
      "          [-1.4309e-01, -7.5710e-02, -7.2215e-02,  ...,  2.0417e-01,\n",
      "            1.6447e-01,  9.5166e-02],\n",
      "          [-8.5925e-02, -4.0134e-02, -5.1491e-02,  ...,  1.6352e-01,\n",
      "            1.4822e-01,  1.0196e-01]],\n",
      "\n",
      "         [[-2.3596e-02, -2.1258e-03, -2.7761e-02,  ...,  3.9940e-02,\n",
      "           -7.1123e-03,  3.2207e-02],\n",
      "          [ 2.5705e-04,  2.2468e-02,  8.9070e-03,  ...,  1.8771e-02,\n",
      "           -1.4155e-02,  1.8275e-02],\n",
      "          [ 5.4084e-03,  2.9397e-02,  3.3051e-04,  ...,  1.2054e-02,\n",
      "           -2.5237e-03,  8.3515e-03],\n",
      "          ...,\n",
      "          [-6.2826e-02, -1.1655e-02, -6.2080e-02,  ...,  1.0332e-01,\n",
      "           -9.4987e-03, -7.9570e-02],\n",
      "          [-4.5691e-02,  3.3726e-03, -3.9632e-02,  ..., -2.6448e-02,\n",
      "           -3.3500e-02, -7.6398e-02],\n",
      "          [-1.8700e-02,  1.1365e-02, -3.9671e-02,  ..., -6.8563e-02,\n",
      "           -4.1289e-02, -5.5473e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9950e-03,  2.9262e-03,  4.8212e-02,  ...,  6.1402e-02,\n",
      "            2.6121e-02,  1.9558e-02],\n",
      "          [-1.2579e-02, -4.8879e-03,  1.8490e-02,  ...,  5.3881e-02,\n",
      "            1.6377e-02,  2.3768e-02],\n",
      "          [ 3.6561e-03, -7.7510e-04,  2.6360e-02,  ..., -2.5849e-02,\n",
      "           -6.1798e-02,  2.6103e-02],\n",
      "          ...,\n",
      "          [-1.0812e-02, -4.6008e-03,  1.5122e-02,  ...,  2.9561e-02,\n",
      "            5.3272e-03,  6.8561e-02],\n",
      "          [ 2.7364e-04, -1.4850e-02,  7.8180e-03,  ...,  2.7172e-02,\n",
      "           -1.8095e-02,  5.2485e-02],\n",
      "          [-5.2470e-02, -4.6578e-02, -1.0951e-02,  ...,  4.3038e-03,\n",
      "           -2.6379e-03,  1.4406e-02]],\n",
      "\n",
      "         [[ 2.3965e-02,  2.2740e-02,  5.7586e-03,  ...,  7.2087e-03,\n",
      "           -2.4652e-02,  4.4658e-02],\n",
      "          [ 2.6914e-02,  4.4892e-02, -1.0872e-03,  ...,  4.4243e-02,\n",
      "           -2.1168e-02,  6.4538e-02],\n",
      "          [ 1.2421e-02,  1.0247e-02, -4.1554e-02,  ..., -1.2134e-01,\n",
      "           -1.6294e-01,  2.6266e-02],\n",
      "          ...,\n",
      "          [ 3.5926e-02,  5.3235e-02,  1.1016e-02,  ...,  1.2710e-02,\n",
      "           -2.9737e-02,  8.5926e-02],\n",
      "          [ 1.5623e-02,  2.1743e-02, -8.2941e-03,  ..., -3.2744e-03,\n",
      "           -5.4099e-02,  5.7634e-02],\n",
      "          [ 7.5254e-02,  8.7784e-02,  5.5804e-02,  ...,  5.2849e-02,\n",
      "            1.0612e-02,  9.3531e-02]],\n",
      "\n",
      "         [[-3.6488e-02,  6.6332e-03, -3.9035e-02,  ..., -1.5678e-02,\n",
      "           -7.9994e-02, -8.8658e-04],\n",
      "          [-5.1740e-03,  5.7395e-02,  8.9841e-03,  ...,  7.4166e-02,\n",
      "           -3.1792e-03,  4.2777e-02],\n",
      "          [-7.9446e-02, -2.2924e-02, -7.3370e-02,  ..., -5.6738e-02,\n",
      "           -1.2923e-01,  1.8896e-02],\n",
      "          ...,\n",
      "          [-3.9394e-02,  3.0981e-02, -2.7901e-02,  ..., -1.6774e-02,\n",
      "           -1.0236e-01,  4.0128e-02],\n",
      "          [-6.0751e-02, -2.3034e-02, -7.6838e-02,  ..., -7.9069e-02,\n",
      "           -1.6195e-01, -1.3746e-02],\n",
      "          [ 7.9522e-03,  4.6969e-02, -1.2460e-02,  ..., -4.6956e-02,\n",
      "           -1.0082e-01,  1.9832e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1702e-02,  1.3825e-02,  9.0514e-03,  ..., -9.6401e-02,\n",
      "           -1.1277e-01, -2.1596e-01],\n",
      "          [-9.0091e-02, -1.3136e-02, -3.2812e-02,  ..., -7.5263e-02,\n",
      "           -1.4803e-01, -2.9966e-01],\n",
      "          [-1.3155e-01, -4.2686e-02, -4.7744e-02,  ...,  2.1429e-01,\n",
      "            3.2543e-02, -1.7151e-01],\n",
      "          ...,\n",
      "          [-1.0621e-01, -9.7966e-02, -2.5551e-01,  ...,  1.2277e-01,\n",
      "            1.9287e-01,  1.2671e-01],\n",
      "          [-8.0761e-02, -6.1498e-02, -2.2312e-01,  ...,  3.5376e-02,\n",
      "            1.0532e-01,  1.0669e-01],\n",
      "          [ 3.8186e-02,  4.9957e-02, -1.2802e-01,  ..., -3.2927e-02,\n",
      "            1.8685e-02,  4.7146e-02]],\n",
      "\n",
      "         [[ 3.9013e-02,  6.4311e-03, -3.1710e-03,  ..., -2.1245e-02,\n",
      "            4.0516e-02,  1.1092e-01],\n",
      "          [ 6.5689e-02,  2.2132e-02,  6.6539e-03,  ..., -3.9448e-02,\n",
      "            2.7749e-02,  1.1404e-01],\n",
      "          [ 7.7954e-02,  4.0220e-02,  1.4047e-02,  ..., -1.5417e-01,\n",
      "           -9.2291e-02,  3.4460e-02],\n",
      "          ...,\n",
      "          [ 1.2836e-01,  9.4449e-02,  1.4659e-01,  ..., -6.0067e-02,\n",
      "           -9.0891e-02, -6.1129e-02],\n",
      "          [ 1.2683e-01,  1.0044e-01,  1.3754e-01,  ..., -2.2507e-02,\n",
      "           -6.6664e-02, -1.9906e-02],\n",
      "          [ 8.0509e-02,  7.8203e-02,  9.8934e-02,  ...,  9.2865e-03,\n",
      "           -3.4635e-02, -1.2395e-02]],\n",
      "\n",
      "         [[ 1.1535e-02, -2.6993e-02,  1.4820e-02,  ...,  9.4833e-02,\n",
      "            1.2044e-01,  1.1027e-01],\n",
      "          [ 9.2629e-03, -2.6680e-02,  1.2218e-02,  ...,  8.7219e-02,\n",
      "            1.5435e-01,  1.8049e-01],\n",
      "          [ 6.9946e-02,  1.3250e-02,  4.8007e-02,  ..., -5.6851e-02,\n",
      "            3.2596e-02,  1.6812e-01],\n",
      "          ...,\n",
      "          [-1.2187e-02, -3.3265e-02,  1.1284e-01,  ..., -6.7740e-02,\n",
      "           -1.0240e-01, -7.6188e-02],\n",
      "          [-6.0069e-03, -2.8631e-02,  1.1643e-01,  ..., -6.7597e-03,\n",
      "           -4.3772e-02, -3.1101e-02],\n",
      "          [-1.3355e-01, -1.4825e-01, -1.0060e-03,  ...,  1.8809e-02,\n",
      "           -6.4637e-03, -2.7061e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.0948e-03,  1.4823e-02,  4.7374e-03,  ...,  1.5540e-02,\n",
      "           -5.8369e-04, -1.9922e-02],\n",
      "          [ 2.8962e-04,  2.1229e-02, -1.3210e-02,  ...,  2.4388e-03,\n",
      "           -5.8485e-03, -2.0373e-02],\n",
      "          [-1.1050e-02,  1.0094e-02, -2.9625e-02,  ..., -1.4471e-02,\n",
      "           -1.7187e-02, -3.0534e-02],\n",
      "          ...,\n",
      "          [ 1.0013e-01,  9.1407e-02,  1.3077e-01,  ...,  1.5798e-01,\n",
      "            9.0361e-02,  7.8365e-02],\n",
      "          [ 1.1610e-01,  8.1846e-02,  8.2892e-02,  ..., -6.0174e-02,\n",
      "           -6.9412e-02, -5.0151e-02],\n",
      "          [-1.0564e-01, -1.1848e-01, -1.7681e-01,  ..., -2.0837e-01,\n",
      "           -1.8036e-01, -1.6691e-01]],\n",
      "\n",
      "         [[-1.1495e-02,  2.4917e-03, -8.2400e-03,  ..., -7.5865e-03,\n",
      "           -1.7387e-02, -1.7026e-02],\n",
      "          [-2.7461e-03, -1.1415e-02, -6.0670e-03,  ..., -2.8248e-02,\n",
      "           -2.2555e-02, -2.2559e-02],\n",
      "          [-8.4246e-03, -2.2378e-03, -3.5825e-02,  ..., -1.8462e-02,\n",
      "           -1.9795e-02, -2.4990e-02],\n",
      "          ...,\n",
      "          [ 1.2956e-01,  9.8057e-02,  1.4888e-01,  ...,  1.5655e-01,\n",
      "            7.9547e-02,  9.6928e-02],\n",
      "          [ 1.6080e-01,  1.0522e-01,  1.0264e-01,  ..., -6.5226e-02,\n",
      "           -6.4314e-02, -3.9066e-02],\n",
      "          [-1.2880e-01, -1.4656e-01, -1.9475e-01,  ..., -2.4177e-01,\n",
      "           -2.0277e-01, -1.9324e-01]],\n",
      "\n",
      "         [[-5.4209e-03, -1.7648e-03,  4.3163e-03,  ...,  9.8182e-03,\n",
      "            5.2347e-03,  6.3336e-03],\n",
      "          [ 9.3478e-03,  1.5920e-03, -2.1660e-03,  ...,  7.1244e-03,\n",
      "            9.3521e-04, -5.7647e-03],\n",
      "          [-1.3668e-03,  3.8899e-03, -7.7412e-03,  ...,  3.0651e-03,\n",
      "            1.4989e-02, -8.1730e-03],\n",
      "          ...,\n",
      "          [ 4.3937e-02,  7.9544e-04,  6.0613e-02,  ...,  7.4787e-02,\n",
      "            4.3960e-02,  5.6071e-02],\n",
      "          [ 1.0077e-01,  7.5126e-02,  1.0962e-01,  ...,  4.9886e-03,\n",
      "            1.0789e-02,  1.3402e-02],\n",
      "          [-8.8773e-02, -7.2790e-02, -9.2907e-02,  ..., -6.6530e-02,\n",
      "           -3.8977e-02, -4.8370e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5712e-03,  4.6908e-02, -1.6075e-02,  ...,  7.7790e-03,\n",
      "           -1.9798e-02,  6.8000e-03],\n",
      "          [ 6.2769e-02,  4.5108e-02,  4.7187e-02,  ...,  6.0599e-02,\n",
      "            2.9275e-02,  5.5794e-02],\n",
      "          [ 3.6748e-03,  1.2952e-02,  1.8988e-05,  ..., -8.3492e-03,\n",
      "           -1.9689e-03,  8.0830e-03],\n",
      "          ...,\n",
      "          [-4.4365e-02, -5.8858e-02, -2.4772e-02,  ..., -2.8423e-02,\n",
      "           -3.0897e-02, -5.2936e-02],\n",
      "          [-9.7572e-03, -4.3227e-02,  9.0068e-03,  ..., -4.2596e-02,\n",
      "           -1.8114e-02, -2.8028e-02],\n",
      "          [-2.2007e-02, -3.3594e-02,  1.3479e-02,  ..., -4.1530e-02,\n",
      "           -1.7819e-02, -5.1977e-02]],\n",
      "\n",
      "         [[-9.0596e-02, -5.1485e-02, -1.6459e-01,  ..., -1.1970e-01,\n",
      "           -1.1150e-01, -4.3914e-02],\n",
      "          [ 1.3835e-02,  2.6007e-02, -1.9440e-02,  ...,  2.3757e-02,\n",
      "            6.3709e-03,  5.4287e-02],\n",
      "          [-9.3225e-02, -4.7454e-02, -1.1274e-01,  ..., -8.6459e-02,\n",
      "           -7.3958e-02, -6.6610e-02],\n",
      "          ...,\n",
      "          [ 2.7382e-02,  1.0310e-02,  4.3906e-02,  ...,  2.7094e-02,\n",
      "            4.4510e-02,  1.5977e-02],\n",
      "          [ 9.8431e-02,  6.1433e-02,  1.1413e-01,  ...,  9.6398e-02,\n",
      "            1.0725e-01,  9.5719e-02],\n",
      "          [-1.5100e-02, -1.1830e-02,  4.8571e-02,  ...,  2.9060e-02,\n",
      "            5.6323e-02, -2.1631e-03]],\n",
      "\n",
      "         [[-1.3693e-01, -7.9341e-02, -2.1245e-01,  ..., -1.3633e-01,\n",
      "           -1.5123e-01, -6.3938e-02],\n",
      "          [ 1.5745e-02,  5.1443e-02, -1.8209e-02,  ...,  4.9085e-02,\n",
      "            1.9585e-02,  7.8095e-02],\n",
      "          [-1.7127e-01, -8.8734e-02, -1.7467e-01,  ..., -1.4431e-01,\n",
      "           -1.3364e-01, -1.1878e-01],\n",
      "          ...,\n",
      "          [ 5.1982e-02,  1.5912e-02,  7.0009e-02,  ...,  4.4396e-02,\n",
      "            6.5429e-02,  2.6919e-02],\n",
      "          [ 1.3144e-01,  9.1333e-02,  1.6228e-01,  ...,  1.4230e-01,\n",
      "            1.5500e-01,  1.3808e-01],\n",
      "          [ 3.7818e-03, -2.0365e-02,  7.8663e-02,  ...,  8.6037e-02,\n",
      "            1.2596e-01,  3.8774e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.5081e-02,  5.6581e-02,  1.4016e-01,  ..., -1.4826e-02,\n",
      "            1.0425e-02, -3.7919e-03],\n",
      "          [ 6.0412e-02,  1.2531e-01, -1.2366e-01,  ...,  7.8628e-02,\n",
      "           -1.0564e-02, -2.2228e-02],\n",
      "          [ 1.0304e-01, -1.3654e-01, -1.9601e-01,  ..., -5.1919e-02,\n",
      "           -8.3287e-02,  3.9678e-02],\n",
      "          ...,\n",
      "          [-1.8598e-01,  1.5479e-02,  3.3912e-01,  ...,  2.7509e-01,\n",
      "            1.0493e-01, -1.6863e-01],\n",
      "          [ 6.8278e-02,  1.3989e-01,  1.1350e-02,  ..., -7.8728e-02,\n",
      "           -2.5001e-01, -8.0072e-02],\n",
      "          [ 5.1736e-03, -6.8372e-02, -9.1940e-02,  ..., -1.0727e-01,\n",
      "            8.7973e-02,  1.0139e-01]],\n",
      "\n",
      "         [[-9.8760e-02,  6.2635e-02,  1.1495e-01,  ..., -1.3191e-02,\n",
      "            1.9574e-02, -1.0864e-03],\n",
      "          [ 8.3206e-02,  1.0300e-01, -1.5419e-01,  ...,  1.0864e-01,\n",
      "            1.2592e-02, -2.0278e-02],\n",
      "          [ 1.1248e-01, -1.6928e-01, -1.8876e-01,  ..., -6.3491e-02,\n",
      "           -9.3101e-02,  4.9006e-02],\n",
      "          ...,\n",
      "          [-1.8867e-01,  6.7374e-02,  4.8128e-01,  ...,  3.1371e-01,\n",
      "            1.6068e-01, -1.3449e-01],\n",
      "          [ 1.1207e-01,  2.0871e-01,  4.6815e-02,  ..., -7.0456e-03,\n",
      "           -2.2978e-01, -6.9528e-02],\n",
      "          [ 1.7255e-02, -9.1683e-02, -1.5943e-01,  ..., -8.0373e-02,\n",
      "            8.0035e-02,  1.1819e-01]],\n",
      "\n",
      "         [[-1.0580e-01,  5.4381e-02,  1.3048e-01,  ..., -3.9546e-02,\n",
      "            1.1924e-02, -2.7886e-03],\n",
      "          [ 5.7859e-02,  1.0646e-01, -1.3468e-01,  ...,  1.0645e-01,\n",
      "            1.8412e-02, -1.3245e-03],\n",
      "          [ 1.0398e-01, -1.0849e-01, -1.6758e-01,  ..., -4.2554e-02,\n",
      "           -8.5875e-02,  5.2581e-02],\n",
      "          ...,\n",
      "          [-1.8241e-01,  5.4228e-02,  3.9395e-01,  ...,  2.4432e-01,\n",
      "            1.0216e-01, -1.2876e-01],\n",
      "          [ 8.5720e-02,  1.8378e-01,  5.0316e-02,  ..., -4.7009e-02,\n",
      "           -2.1584e-01, -4.2482e-02],\n",
      "          [ 3.9612e-02, -7.6353e-02, -1.3502e-01,  ..., -4.8630e-02,\n",
      "            1.0063e-01,  9.0307e-02]]]], requires_grad=True)\n",
      "name = features.0.bias param = Parameter containing:\n",
      "tensor([-0.9705, -2.8070, -0.0371, -0.0795, -0.1159,  0.0252, -0.0752, -1.4181,\n",
      "         1.6454, -0.0990, -0.0161, -0.1282, -0.0658, -0.0345, -0.0743, -1.2977,\n",
      "        -0.0505,  0.0121, -0.1013, -1.1887, -0.1380, -0.0492, -0.0789, -0.0405,\n",
      "        -0.0958, -0.0705, -1.9374, -0.0850, -0.1388, -0.1968, -0.1279, -2.0095,\n",
      "        -0.0476, -0.0604, -0.0351, -0.3843, -2.7823,  0.6605, -0.1655, -2.1293,\n",
      "         0.0543, -0.0274, -0.1703, -0.0593, -0.4215, -1.9394, -1.2094,  0.0153,\n",
      "        -0.1081, -0.0248, -0.1503, -1.8516, -0.0928, -0.0177, -0.0700, -0.0582,\n",
      "        -0.0630, -0.0721, -1.2678, -0.1176, -0.0441, -0.3259,  0.0507, -0.0146],\n",
      "       requires_grad=True)\n",
      "name = features.3.weight param = Parameter containing:\n",
      "tensor([[[[ 3.6245e-03,  1.4335e-03,  3.7217e-02, -2.0926e-02,  1.8121e-03],\n",
      "          [ 2.4126e-02, -1.2056e-02,  7.1170e-02, -8.5224e-02,  1.3067e-02],\n",
      "          [ 2.0966e-02, -1.0623e-01,  2.1572e-02, -6.9547e-02,  3.1583e-02],\n",
      "          [-8.3392e-03, -3.9020e-02, -4.6621e-02,  2.2133e-02, -1.3252e-03],\n",
      "          [-1.5370e-02,  8.6569e-03,  3.1479e-02,  1.6698e-02, -4.7130e-03]],\n",
      "\n",
      "         [[-5.4573e-03, -1.9087e-02, -3.2424e-02, -2.2006e-02, -1.2120e-02],\n",
      "          [-7.4972e-03,  3.0946e-02,  3.1899e-02, -7.6327e-03, -1.4720e-02],\n",
      "          [ 5.4830e-03,  8.0306e-02,  6.1262e-02,  1.3252e-02,  2.6240e-02],\n",
      "          [-2.6938e-02,  5.9188e-03,  3.8373e-02, -6.3116e-03,  3.9863e-03],\n",
      "          [ 2.0844e-03, -3.6292e-02, -2.1987e-03, -1.6570e-02,  5.6354e-03]],\n",
      "\n",
      "         [[-1.2587e-02, -5.9436e-02, -9.6281e-02,  1.6745e-02,  4.7471e-02],\n",
      "          [-1.5036e-02, -1.1214e-01, -2.3924e-02,  3.3459e-02,  4.1306e-02],\n",
      "          [-1.3845e-02,  4.1235e-02,  2.1580e-01,  2.9520e-02, -5.8914e-02],\n",
      "          [ 1.2300e-02,  1.0087e-01,  2.1916e-02, -1.4008e-01, -3.1255e-02],\n",
      "          [ 3.7845e-02,  5.2634e-02, -8.0348e-03, -8.1815e-02,  1.4355e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2711e-02,  2.5915e-02,  4.1726e-02, -1.3706e-02,  1.4752e-03],\n",
      "          [-1.0794e-02,  1.6434e-02,  8.1224e-02, -6.0144e-02, -5.1132e-02],\n",
      "          [-1.3769e-02, -5.3764e-02,  1.1054e-01,  3.8881e-03, -5.8872e-02],\n",
      "          [ 5.1748e-04,  2.3237e-02,  6.1570e-02,  5.5012e-02, -1.8824e-02],\n",
      "          [-4.0024e-03,  9.4621e-03, -2.7666e-02, -3.6102e-03, -6.4362e-03]],\n",
      "\n",
      "         [[-9.5948e-04, -5.7705e-03,  4.5656e-02,  1.4085e-02, -4.3562e-02],\n",
      "          [-4.4058e-03, -3.2867e-02,  4.1615e-02, -1.0995e-02,  2.3037e-02],\n",
      "          [ 1.7953e-02,  5.5599e-03, -4.6110e-02, -6.3326e-02,  2.5256e-02],\n",
      "          [ 5.1608e-03,  4.1085e-02,  2.1804e-02,  1.9433e-02,  3.1380e-02],\n",
      "          [-2.9532e-02, -3.1130e-03,  5.4939e-02,  3.5771e-02, -3.1513e-03]],\n",
      "\n",
      "         [[ 1.7368e-03,  1.5858e-02, -3.9606e-02, -8.6650e-02,  4.2392e-02],\n",
      "          [ 3.2755e-02,  2.0259e-02,  1.4398e-01, -1.5988e-01, -1.1522e-01],\n",
      "          [ 1.1646e-02, -1.3281e-01,  2.5051e-01,  1.9387e-01, -1.4720e-01],\n",
      "          [ 2.9876e-02, -7.6454e-02, -1.3301e-01,  1.2492e-01,  3.0456e-02],\n",
      "          [ 4.8693e-02,  7.8451e-02, -3.9283e-02,  4.8439e-03,  2.0383e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1691e-02, -4.7307e-02,  3.3946e-02,  6.8847e-03,  2.6204e-02],\n",
      "          [ 1.7683e-02, -5.2123e-02, -6.2835e-02, -3.3933e-02,  1.9128e-02],\n",
      "          [ 9.2291e-03, -2.8800e-02, -1.8724e-01, -1.9551e-02, -2.1082e-02],\n",
      "          [-1.4346e-02,  5.7543e-02, -4.1899e-02,  6.3682e-03,  4.2324e-04],\n",
      "          [ 1.2244e-02,  2.3090e-02, -2.2817e-02,  2.3080e-03, -6.4166e-03]],\n",
      "\n",
      "         [[ 4.6469e-03,  7.4133e-03, -4.1122e-02,  2.9806e-02, -1.8110e-02],\n",
      "          [ 9.6099e-03,  3.9877e-02, -4.1848e-02,  6.9251e-03, -2.5908e-02],\n",
      "          [-1.0007e-02,  5.4747e-02,  2.6736e-02,  7.0483e-03,  2.6949e-02],\n",
      "          [-9.5527e-03, -3.6075e-02,  1.4897e-02, -1.2595e-02, -1.8202e-02],\n",
      "          [-1.4465e-04, -6.3873e-02,  5.8016e-02,  2.8762e-02, -9.7704e-04]],\n",
      "\n",
      "         [[-4.5600e-02,  9.9321e-02,  2.0830e-02, -1.7641e-02,  4.3317e-03],\n",
      "          [-1.1306e-01,  1.0613e-01,  1.2299e-01, -1.5599e-02,  1.1943e-02],\n",
      "          [-8.6221e-02,  5.1575e-02,  2.8114e-01,  3.8475e-03,  3.9631e-02],\n",
      "          [ 2.7465e-02, -9.6338e-02,  1.6717e-01,  1.7882e-02, -3.1237e-02],\n",
      "          [ 3.8818e-02, -1.5017e-01,  9.5537e-02,  8.2108e-02, -2.6467e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1779e-03,  8.2149e-03,  2.2985e-02, -4.9943e-03, -2.2914e-02],\n",
      "          [ 4.4609e-03,  4.6661e-02,  3.4394e-02,  5.2542e-02, -1.8957e-02],\n",
      "          [-1.4202e-02,  5.9543e-02,  6.0551e-03,  3.6463e-02,  3.2430e-04],\n",
      "          [-2.9488e-02,  4.5902e-02,  5.4980e-02, -2.6936e-03,  4.2663e-03],\n",
      "          [-2.9711e-02, -1.6390e-02,  3.4428e-02, -9.1090e-03, -9.7971e-03]],\n",
      "\n",
      "         [[ 2.0002e-02, -4.4658e-03, -2.8359e-02,  7.4180e-03, -5.3517e-03],\n",
      "          [ 1.3052e-02, -2.9312e-02, -6.5957e-02,  3.1932e-02, -2.3129e-03],\n",
      "          [ 1.4003e-02, -5.7715e-02, -9.1541e-02,  2.8261e-03,  1.8726e-02],\n",
      "          [-1.8143e-02, -4.5023e-02, -9.9762e-03,  1.2348e-02, -1.4161e-03],\n",
      "          [ 3.3575e-03,  1.8285e-02,  1.2383e-02, -2.0430e-02,  2.4573e-02]],\n",
      "\n",
      "         [[-5.4195e-03,  4.5804e-04,  1.7469e-02, -2.2458e-03,  1.7530e-03],\n",
      "          [-1.0281e-02,  3.1367e-02, -2.5485e-02,  1.2870e-02, -7.0466e-04],\n",
      "          [-6.3459e-03,  7.3701e-02, -2.9366e-02,  4.9803e-02,  2.5816e-02],\n",
      "          [-1.9934e-02,  3.8506e-02,  3.0833e-02,  2.5688e-03, -4.4185e-03],\n",
      "          [ 1.8114e-03,  2.3094e-02,  4.6518e-02, -3.3974e-02, -1.1660e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0163e-02, -3.7849e-02, -4.6664e-02, -9.7829e-03,  3.7624e-02],\n",
      "          [ 1.4684e-01, -6.4947e-02, -3.7485e-02, -9.2710e-03,  2.3640e-02],\n",
      "          [ 1.8563e-02, -3.5328e-02, -9.6485e-03,  1.4210e-02,  2.7077e-02],\n",
      "          [-6.7717e-03,  2.8039e-03,  4.6860e-03,  4.7567e-03, -6.6633e-03],\n",
      "          [ 2.2155e-02, -1.2387e-03,  3.1133e-02,  3.1837e-02,  2.4495e-03]],\n",
      "\n",
      "         [[ 2.2964e-02, -3.2592e-02, -1.7921e-02,  5.2390e-03,  3.7561e-03],\n",
      "          [ 3.8685e-02, -8.8764e-02, -5.3735e-02, -2.4427e-02,  1.7369e-02],\n",
      "          [ 5.5512e-02, -7.1237e-02, -6.5386e-02, -3.7746e-02,  7.1429e-03],\n",
      "          [ 3.1539e-02, -6.1858e-02, -7.4455e-02, -3.4278e-02, -9.2922e-03],\n",
      "          [ 4.5122e-02, -8.4307e-03, -2.0509e-02, -1.4743e-02,  1.0508e-03]],\n",
      "\n",
      "         [[-9.5345e-03, -2.3179e-02, -1.4264e-02, -6.7151e-03, -2.8285e-02],\n",
      "          [ 1.6202e-01, -2.8234e-02, -2.4645e-02, -1.0152e-02, -2.4914e-02],\n",
      "          [ 8.9119e-02, -2.6843e-02, -3.7465e-02, -7.5062e-03, -1.9929e-03],\n",
      "          [-4.5296e-02, -1.7844e-02, -5.1039e-03,  1.7445e-02,  1.3994e-02],\n",
      "          [-2.0449e-02, -8.8112e-04,  1.3139e-02,  1.8497e-03, -5.4345e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5179e-02,  8.3908e-03, -3.4752e-03, -6.7056e-03,  9.4571e-03],\n",
      "          [ 1.4773e-01,  1.8297e-02, -8.2707e-03, -2.6735e-03, -2.9689e-03],\n",
      "          [ 1.8945e-02, -2.4611e-02, -2.5792e-02,  5.7622e-03,  1.5490e-02],\n",
      "          [ 1.0744e-02, -2.2880e-03,  1.3852e-02, -3.0690e-03, -1.4038e-03],\n",
      "          [ 3.5738e-03, -1.7099e-02, -2.0962e-03, -5.2738e-04, -1.1953e-02]],\n",
      "\n",
      "         [[-1.8036e-02,  5.5999e-03, -4.3933e-03, -6.4853e-03,  1.1134e-02],\n",
      "          [ 8.3012e-02, -8.5719e-02, -2.3690e-02,  2.7197e-02,  1.5338e-02],\n",
      "          [ 1.6264e-02, -5.0213e-02, -2.9401e-02, -6.0407e-04,  1.5086e-02],\n",
      "          [ 1.2260e-02,  6.5707e-03, -2.8775e-03, -2.0055e-02,  4.6619e-03],\n",
      "          [ 1.4575e-02, -9.5385e-03, -2.4609e-02, -2.4521e-03,  1.0301e-03]],\n",
      "\n",
      "         [[-1.7248e-02,  7.3069e-03,  1.0429e-02, -1.4917e-02, -6.8504e-03],\n",
      "          [ 6.2874e-02, -3.2599e-02,  5.7802e-03,  1.4551e-02, -6.1276e-03],\n",
      "          [ 7.3852e-03, -6.0841e-02, -1.0494e-02,  3.6026e-03, -1.4746e-02],\n",
      "          [-1.7262e-02,  1.5815e-03, -2.3888e-02, -9.7895e-03, -7.4106e-03],\n",
      "          [ 6.9352e-03,  7.2060e-03, -1.9073e-02, -6.7136e-03,  6.1392e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7579e-02,  1.0168e-02,  4.4818e-02, -2.6664e-03, -2.2669e-02],\n",
      "          [-1.5147e-02, -3.2701e-02,  1.4564e-02, -1.2843e-02, -3.2623e-02],\n",
      "          [-3.0235e-02, -3.2706e-02, -3.4020e-02, -2.0842e-02, -3.2697e-02],\n",
      "          [-4.2032e-03, -3.4967e-03, -1.0389e-02, -9.6090e-03, -3.1508e-03],\n",
      "          [ 1.1118e-02,  8.8342e-03,  1.8196e-02,  7.5631e-03,  1.5709e-03]],\n",
      "\n",
      "         [[-9.1671e-03,  1.0798e-03, -2.4020e-02, -1.7457e-02, -7.8634e-03],\n",
      "          [-1.5174e-02,  1.8126e-02,  1.3363e-02,  7.1205e-02,  5.8289e-02],\n",
      "          [-1.0982e-02,  1.5266e-02, -2.4875e-02, -4.0705e-03, -2.4844e-02],\n",
      "          [ 2.7485e-03,  1.6571e-02, -3.2608e-02, -5.6266e-02, -3.9944e-02],\n",
      "          [-4.9014e-04,  1.9889e-02, -3.3673e-03, -2.2187e-02, -9.5482e-03]],\n",
      "\n",
      "         [[-2.6544e-02, -4.6466e-02, -1.1130e-01, -6.3725e-02,  2.4153e-02],\n",
      "          [-3.1451e-02, -4.6735e-02, -5.0069e-02,  3.6642e-02,  8.7667e-02],\n",
      "          [ 2.4192e-02,  2.9334e-02,  5.9852e-02,  4.2028e-02, -2.5984e-02],\n",
      "          [ 2.5426e-02,  1.8227e-02,  4.0526e-02, -8.6688e-03, -6.0653e-02],\n",
      "          [ 1.2664e-02,  1.5354e-02,  3.3492e-02,  1.3319e-02, -2.3908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5345e-02, -2.7450e-02, -3.7116e-02,  4.8070e-02,  1.0182e-02],\n",
      "          [-5.4621e-02, -6.3059e-02, -5.1834e-02,  6.4004e-02,  2.5790e-02],\n",
      "          [ 1.6780e-02,  1.3105e-02, -3.9535e-02, -1.2138e-03,  9.2518e-03],\n",
      "          [ 1.4997e-02,  1.2259e-02, -2.3395e-02, -2.8443e-02,  2.4942e-02],\n",
      "          [-4.0684e-03,  1.4466e-02,  6.2136e-03, -2.2554e-02, -2.0291e-03]],\n",
      "\n",
      "         [[-3.5230e-02,  8.0857e-03,  2.3528e-02, -1.0179e-02, -2.1804e-03],\n",
      "          [-3.4595e-02,  3.9871e-03,  1.3592e-02, -7.9822e-02, -5.2531e-02],\n",
      "          [-3.2725e-02,  3.4170e-02,  2.6620e-02, -2.4204e-03,  2.4924e-02],\n",
      "          [ 1.8057e-02,  4.6391e-03, -1.2008e-02,  8.8407e-03,  1.9375e-02],\n",
      "          [-2.9099e-02,  1.2933e-04, -1.7477e-02,  4.3010e-02,  6.6167e-02]],\n",
      "\n",
      "         [[ 4.6078e-02,  2.8413e-02, -2.6394e-02,  4.7513e-03, -7.6480e-02],\n",
      "          [ 7.5960e-02,  4.4307e-02, -5.8771e-02,  1.7854e-02,  9.6082e-02],\n",
      "          [ 5.8415e-02,  3.7583e-02, -6.7510e-02, -1.0312e-01, -2.3266e-02],\n",
      "          [ 4.3488e-02,  6.0671e-02,  6.2699e-02,  3.7197e-03, -5.8098e-02],\n",
      "          [ 7.3890e-05,  2.7182e-02,  4.3226e-02,  3.1200e-02, -5.9276e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5983e-02, -2.5757e-02, -2.7917e-02, -6.0154e-02, -2.1587e-02],\n",
      "          [ 5.8470e-03, -4.0597e-02, -9.7084e-02, -1.1321e-01, -4.5251e-02],\n",
      "          [-3.3056e-02, -1.7874e-02, -9.1402e-02, -1.0827e-01, -5.3423e-02],\n",
      "          [-1.4856e-02, -3.3450e-03, -2.7355e-02, -4.8538e-02, -4.1184e-02],\n",
      "          [ 9.0377e-04, -1.8180e-02, -3.1040e-02, -1.1854e-02, -2.6462e-02]],\n",
      "\n",
      "         [[ 7.2521e-02,  1.6407e-02, -1.5754e-01, -8.8864e-02, -2.1638e-02],\n",
      "          [ 9.2281e-02,  8.5642e-02, -6.8582e-02, -7.8368e-02, -9.3343e-02],\n",
      "          [ 1.1667e-01,  1.4296e-01,  1.4621e-02, -6.6599e-02, -1.8653e-01],\n",
      "          [ 4.0418e-02,  8.7898e-02,  4.2521e-02, -8.9029e-03, -1.2440e-01],\n",
      "          [ 2.0246e-02,  6.5828e-02,  9.6516e-02,  5.8696e-02, -7.2705e-02]],\n",
      "\n",
      "         [[-3.7801e-02, -1.1232e-02, -8.1927e-03,  1.2744e-02,  6.8491e-02],\n",
      "          [-4.4532e-03, -9.6229e-03, -3.2608e-02,  2.9350e-03,  3.7486e-02],\n",
      "          [ 3.3585e-02,  4.8458e-02,  2.6881e-02, -6.1178e-02, -2.1019e-02],\n",
      "          [-1.9669e-02,  6.9724e-03,  4.2018e-02, -4.3931e-02, -7.6382e-02],\n",
      "          [ 8.3337e-03,  2.5425e-03,  2.8063e-02, -3.4867e-02, -8.6687e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2673e-02, -1.5327e-02,  1.6517e-02,  3.3334e-02,  1.3038e-02],\n",
      "          [ 1.6805e-03, -1.8921e-02, -3.6130e-02,  3.2359e-02,  5.0130e-02],\n",
      "          [-1.3607e-02, -3.3703e-02, -7.9256e-02, -5.1558e-03,  6.5082e-02],\n",
      "          [-1.3499e-03,  1.9183e-02, -1.2600e-03, -1.5375e-02,  9.9117e-03],\n",
      "          [-8.6383e-03, -6.4556e-03,  4.4472e-03, -7.7968e-04,  2.6764e-02]],\n",
      "\n",
      "         [[-3.1357e-02, -6.5565e-02, -4.5553e-02,  2.9694e-02,  5.0477e-02],\n",
      "          [ 2.6388e-02, -6.5116e-03, -1.4299e-01, -2.9214e-02,  1.2134e-03],\n",
      "          [ 5.2430e-02,  6.1108e-02, -2.8583e-02, -1.0998e-01, -3.4642e-02],\n",
      "          [ 1.6018e-02,  3.1906e-02,  7.7014e-02, -1.1630e-02, -5.6960e-02],\n",
      "          [ 4.9326e-02, -1.5627e-02,  4.2784e-02,  3.7805e-02, -2.6815e-02]],\n",
      "\n",
      "         [[ 9.0381e-03,  1.6271e-03,  9.9757e-03,  2.6084e-02,  6.8623e-03],\n",
      "          [ 1.0622e-02, -6.1560e-03, -9.2547e-03,  1.8062e-02,  2.2674e-02],\n",
      "          [ 2.8991e-02,  1.2231e-04, -1.6760e-02, -1.9807e-03,  3.1453e-02],\n",
      "          [ 1.8964e-02,  2.8631e-02,  5.8559e-04, -1.0603e-02,  1.1077e-02],\n",
      "          [ 5.4998e-03, -6.3534e-03,  2.9878e-03, -2.7331e-02, -2.4437e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0352e-03, -2.0708e-02, -1.9059e-02, -2.8221e-03,  9.0732e-03],\n",
      "          [-2.2202e-02, -3.6482e-02, -3.3435e-02, -2.0294e-02, -1.1695e-02],\n",
      "          [-7.7194e-03, -3.2950e-02, -5.5740e-02, -3.5089e-02, -1.5053e-02],\n",
      "          [-1.2823e-02, -3.5408e-02, -4.2076e-02, -1.6718e-02, -1.8323e-02],\n",
      "          [-3.9433e-03,  5.0854e-03, -2.3092e-03,  1.1569e-02,  1.1675e-02]],\n",
      "\n",
      "         [[ 1.8536e-02,  2.3997e-02,  1.8607e-02, -2.1316e-03,  3.0036e-02],\n",
      "          [-9.1898e-03, -2.0234e-02, -2.0921e-02, -1.5293e-02, -4.1515e-03],\n",
      "          [-2.5399e-02, -3.6147e-02,  1.1215e-02, -1.3978e-02,  1.0484e-02],\n",
      "          [-1.7011e-03, -1.7085e-02,  1.9866e-02,  6.1436e-03,  4.9555e-03],\n",
      "          [ 1.0626e-02,  1.2917e-02,  4.2516e-02,  1.5874e-02,  1.7050e-02]],\n",
      "\n",
      "         [[-4.0153e-03,  1.6083e-02,  8.7844e-03, -9.1274e-03,  2.2305e-02],\n",
      "          [-2.0949e-02, -3.9927e-03, -3.2194e-02, -2.1123e-02, -1.3385e-03],\n",
      "          [-4.2372e-03,  1.4911e-02,  3.8126e-03, -5.2412e-03,  9.8842e-03],\n",
      "          [ 1.2249e-02,  3.7495e-03, -3.4932e-03,  6.0049e-03,  1.4841e-02],\n",
      "          [ 1.3200e-02, -1.9996e-03,  2.0933e-02,  1.6309e-04, -8.3707e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4706e-03, -3.2926e-02, -1.5733e-02, -1.7831e-02,  2.1256e-03],\n",
      "          [-5.4066e-02, -5.4719e-02, -4.5444e-02, -5.6256e-02, -3.6743e-02],\n",
      "          [ 2.8305e-02,  2.9538e-02,  4.4844e-02,  2.2081e-02,  3.5385e-02],\n",
      "          [ 1.6821e-02,  1.6557e-02,  5.4560e-02,  1.7084e-02,  2.3373e-02],\n",
      "          [-4.0657e-03, -8.0451e-03,  4.4215e-04,  7.5198e-03,  1.0919e-02]],\n",
      "\n",
      "         [[ 2.0678e-02,  2.0736e-02,  7.6578e-02,  2.9091e-02,  4.1559e-02],\n",
      "          [-1.0118e-03,  5.5359e-02,  1.3228e-01,  6.7964e-02,  4.1530e-02],\n",
      "          [-3.9346e-03,  3.5696e-02,  1.2877e-01,  6.1861e-02,  2.9380e-02],\n",
      "          [ 2.5981e-02,  3.8598e-02,  1.3250e-01,  3.2665e-02, -1.8039e-02],\n",
      "          [-1.9937e-02, -1.3913e-02, -1.0549e-02, -1.3653e-02, -2.4947e-03]],\n",
      "\n",
      "         [[ 7.0426e-02,  2.1494e-02, -9.1289e-03, -9.1144e-03, -5.7207e-03],\n",
      "          [ 3.0881e-02, -1.0100e-02, -5.8352e-02, -3.8790e-02, -2.0214e-02],\n",
      "          [-7.5705e-03, -4.3871e-02, -8.5624e-02, -5.4874e-02, -1.8760e-02],\n",
      "          [-5.6932e-03, -4.2488e-02, -7.0337e-02, -3.9515e-02,  2.8042e-03],\n",
      "          [ 4.9093e-02,  8.0856e-03, -2.0497e-02,  1.7022e-02,  2.4330e-02]]]],\n",
      "       requires_grad=True)\n",
      "name = features.3.bias param = Parameter containing:\n",
      "tensor([-1.0928e-01, -1.7263e-01, -5.1698e-02, -6.5495e-02, -3.9439e-02,\n",
      "         1.7420e-01, -1.8464e-01,  9.5525e-02, -2.5099e-02, -3.0075e-02,\n",
      "         1.3654e-01, -3.2269e-01, -1.4834e-01,  1.2790e-01,  4.0678e-03,\n",
      "        -5.7279e-02, -2.1440e-03,  2.0314e-01,  3.3098e-01,  7.3128e-02,\n",
      "         4.9798e-01, -4.4765e-02, -8.2151e-02,  1.4895e-02, -4.6373e-02,\n",
      "         5.7510e-02,  1.9020e-02,  7.4533e-04, -1.8182e-01, -1.2202e-04,\n",
      "        -1.3162e-01, -1.2743e-01,  5.9956e-03, -4.2740e-01,  1.1648e-01,\n",
      "        -1.6375e-01, -6.0307e-02, -2.3113e-01,  2.4188e-01, -7.8616e-02,\n",
      "         2.0777e-02, -2.5044e-02, -4.4685e-02,  2.8326e-02, -1.7459e-01,\n",
      "         7.1566e-02, -5.7368e-02,  1.2070e-01, -5.8133e-02, -1.7347e-01,\n",
      "        -1.2782e-01,  5.3739e-02,  4.5314e-02,  9.4975e-02,  1.0401e-02,\n",
      "         1.3877e-01, -1.3664e-01,  2.4293e-01,  1.4512e-01,  4.8102e-01,\n",
      "        -1.1793e-01, -1.5927e-01,  1.6019e-01,  2.2559e-01,  9.6043e-02,\n",
      "         2.9943e-02, -1.7576e-01, -9.5031e-02,  2.3446e-01, -2.4519e-01,\n",
      "         1.0253e-01, -2.4316e-01, -5.6964e-02, -2.7844e-02, -3.4611e-01,\n",
      "         4.0740e-02, -2.3085e-01,  1.9122e-01,  1.6288e-01,  2.9599e-01,\n",
      "        -1.3699e-01,  5.2276e-03, -1.6603e-01, -7.7020e-02, -1.1686e-01,\n",
      "         6.8327e-02, -9.8369e-02, -9.1281e-02, -1.6490e-01,  6.2494e-02,\n",
      "         1.0231e-01, -5.7519e-03, -1.7242e-01, -8.5797e-03, -1.2002e-01,\n",
      "        -1.8632e-01, -5.3833e-02, -6.7391e-02, -1.4795e-01,  2.6208e-02,\n",
      "         3.9989e-02, -2.1992e-01, -1.4985e-01, -8.3122e-02, -6.7938e-02,\n",
      "        -7.8998e-02, -4.2145e-02,  3.7165e-01, -1.8347e-01,  6.1246e-02,\n",
      "        -4.7721e-01, -2.1703e-01, -7.0511e-02, -9.9998e-02, -4.4748e-02,\n",
      "         8.6560e-02, -1.3605e-01, -1.8263e-01, -3.7893e-02, -2.9278e-01,\n",
      "        -1.3911e-01,  1.4130e-01,  2.9491e-01,  2.7607e-01, -4.4584e-02,\n",
      "         3.6733e-01,  8.7795e-02, -2.0914e-02,  2.0941e-01,  4.9935e-01,\n",
      "         1.4991e-01, -1.3268e-01,  2.1515e-01,  2.3250e-01,  1.4488e-01,\n",
      "        -8.2328e-02, -3.2715e-02, -1.2761e-01,  1.1177e-01,  3.8759e-01,\n",
      "        -3.7940e-02, -1.7950e-01,  3.1519e-01, -4.0012e-02,  3.2606e-01,\n",
      "         1.0944e-02, -4.2019e-01, -1.9330e-01,  4.6443e-02,  1.4548e-02,\n",
      "         4.1791e-02,  1.4871e-01, -1.5567e-01, -1.6159e-01,  4.9127e-01,\n",
      "        -1.4576e-01,  1.3040e-01, -3.2479e-02, -3.3374e-02, -3.0722e-01,\n",
      "         3.0348e-01, -8.2917e-02,  1.5031e-01, -2.1193e-02,  1.7708e-01,\n",
      "         2.0579e-01,  1.0637e-01, -1.4460e-01, -1.6046e-01, -2.6753e-02,\n",
      "        -6.7287e-02,  4.8736e-01,  1.7410e-01,  1.8411e-01, -8.9367e-02,\n",
      "         1.4409e-01,  5.3045e-02, -1.3101e-01, -8.4564e-02, -3.6975e-02,\n",
      "        -2.3806e-01, -8.0580e-02, -9.7469e-02,  1.4895e-01, -3.0727e-03,\n",
      "         2.8690e-01,  9.3942e-02,  1.2006e-01, -1.2438e-01,  7.2421e-02,\n",
      "         1.3842e-02,  7.2982e-02], requires_grad=True)\n",
      "name = features.6.weight param = Parameter containing:\n",
      "tensor([[[[ 2.4858e-02,  1.3116e-02,  2.8198e-02],\n",
      "          [ 4.2541e-02,  5.7339e-02, -6.0905e-03],\n",
      "          [-4.1912e-03,  9.3096e-03, -1.5442e-02]],\n",
      "\n",
      "         [[-3.8954e-03, -7.8586e-02, -5.1808e-02],\n",
      "          [ 2.6484e-02, -4.9877e-02, -1.7763e-03],\n",
      "          [ 8.2902e-03, -4.9339e-02,  3.1145e-02]],\n",
      "\n",
      "         [[ 1.6455e-02, -1.2150e-02,  1.7428e-02],\n",
      "          [ 5.2012e-02, -6.7141e-03,  2.7325e-02],\n",
      "          [ 7.5568e-03, -4.2402e-02, -2.7909e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7289e-04,  2.4099e-02,  3.6948e-02],\n",
      "          [-2.4145e-02, -3.5276e-02,  3.6910e-03],\n",
      "          [ 1.9541e-02, -3.0342e-02, -3.5262e-02]],\n",
      "\n",
      "         [[ 1.3239e-02, -1.8624e-02, -5.3330e-02],\n",
      "          [ 1.7639e-04, -1.4714e-02, -2.2829e-02],\n",
      "          [-6.7702e-03,  2.3287e-02,  1.3873e-02]],\n",
      "\n",
      "         [[ 3.0512e-02,  7.5860e-03,  4.9459e-04],\n",
      "          [-4.5703e-03, -1.2827e-02, -6.5061e-03],\n",
      "          [-9.8111e-03, -1.5570e-02,  1.9379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3660e-02, -3.9180e-02,  2.0014e-02],\n",
      "          [ 5.7389e-02,  1.1934e-02,  2.3058e-02],\n",
      "          [-2.2237e-02, -1.8879e-02, -2.0941e-02]],\n",
      "\n",
      "         [[-1.3402e-02,  1.9384e-02,  2.0018e-02],\n",
      "          [ 2.2285e-03, -1.5328e-02, -2.0604e-02],\n",
      "          [ 5.2206e-02, -4.0713e-02, -1.6011e-02]],\n",
      "\n",
      "         [[ 8.2728e-03, -1.2311e-02, -2.6974e-02],\n",
      "          [ 2.5519e-03, -5.6930e-03, -5.1476e-02],\n",
      "          [-2.8822e-02, -8.5134e-02, -6.5895e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1531e-02,  2.4226e-02,  6.0344e-04],\n",
      "          [-3.3641e-02,  7.7504e-02, -1.8122e-02],\n",
      "          [ 2.2435e-02,  6.3408e-02, -1.0774e-03]],\n",
      "\n",
      "         [[-1.6893e-02,  5.7512e-03,  3.7639e-02],\n",
      "          [-1.6503e-02, -3.2492e-03,  3.6293e-02],\n",
      "          [ 3.2918e-02, -1.2321e-02,  1.4753e-03]],\n",
      "\n",
      "         [[ 5.8365e-02,  6.4994e-02,  6.6423e-02],\n",
      "          [-1.3995e-02, -2.4027e-02, -1.2127e-02],\n",
      "          [ 2.6365e-03, -1.4931e-02, -7.9207e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0889e-03,  9.6816e-03, -1.2593e-02],\n",
      "          [ 1.1684e-02,  4.7408e-02,  4.9439e-02],\n",
      "          [-1.1663e-02,  7.7298e-02,  2.3240e-02]],\n",
      "\n",
      "         [[ 9.5861e-03, -3.5039e-02, -1.5836e-02],\n",
      "          [-2.2685e-02,  1.6363e-02,  1.8725e-02],\n",
      "          [-1.7577e-02, -5.9963e-03, -1.2350e-02]],\n",
      "\n",
      "         [[-3.9020e-03, -5.0362e-03,  2.8650e-03],\n",
      "          [ 2.3688e-02,  3.0239e-03, -5.0350e-02],\n",
      "          [-3.0330e-02, -2.0917e-02, -9.9929e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3766e-02, -4.8649e-03,  3.4593e-03],\n",
      "          [-1.7299e-03,  9.8713e-03,  3.1695e-03],\n",
      "          [-1.5713e-02,  2.4070e-02,  4.3523e-02]],\n",
      "\n",
      "         [[ 1.7398e-02,  3.9648e-02,  5.0599e-02],\n",
      "          [-1.8082e-02,  2.3186e-02,  7.5082e-02],\n",
      "          [-1.4652e-02, -1.4806e-03,  2.4491e-02]],\n",
      "\n",
      "         [[-3.6486e-03,  1.6976e-02,  9.5258e-03],\n",
      "          [ 8.3009e-03,  3.0063e-03, -3.5994e-03],\n",
      "          [-2.0521e-04, -9.6109e-04, -7.6914e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1159e-02,  3.1025e-02, -5.1508e-04],\n",
      "          [-2.0021e-02, -9.5897e-03,  2.7262e-02],\n",
      "          [-9.7968e-03, -3.9145e-02,  9.2344e-03]],\n",
      "\n",
      "         [[-2.2890e-02, -6.2061e-03, -1.8220e-02],\n",
      "          [ 2.6104e-02,  1.8208e-02, -3.5678e-02],\n",
      "          [-1.9037e-02, -2.5568e-02, -3.2400e-03]],\n",
      "\n",
      "         [[ 4.5357e-04,  1.1460e-02,  3.0362e-02],\n",
      "          [ 2.1339e-02,  1.1392e-02,  1.3384e-02],\n",
      "          [ 2.2492e-02, -1.0258e-02, -5.8449e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7361e-02,  1.4307e-02,  1.8851e-02],\n",
      "          [ 3.9169e-02, -4.1835e-02, -1.2617e-03],\n",
      "          [-2.4972e-02, -6.0201e-02,  1.1093e-02]],\n",
      "\n",
      "         [[ 1.3269e-02,  2.8252e-02, -2.0582e-02],\n",
      "          [ 1.2612e-02,  5.3777e-02, -2.9175e-02],\n",
      "          [ 4.3714e-02,  1.5523e-02, -3.4617e-02]],\n",
      "\n",
      "         [[-1.4312e-02, -1.1627e-02, -8.0607e-03],\n",
      "          [-1.7464e-02,  9.4876e-03, -3.3993e-04],\n",
      "          [-4.5948e-03,  2.4349e-02,  2.9515e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3024e-02,  3.7754e-02, -7.9412e-03],\n",
      "          [ 2.3338e-02, -3.2373e-02, -4.1358e-02],\n",
      "          [ 6.4814e-02,  2.6370e-02,  4.9119e-02]],\n",
      "\n",
      "         [[ 4.7991e-02, -2.4855e-02,  1.2162e-02],\n",
      "          [-2.7339e-02,  3.9421e-02, -1.8773e-02],\n",
      "          [-5.8830e-02,  2.6058e-02,  1.4781e-03]],\n",
      "\n",
      "         [[ 8.6110e-03, -2.6908e-02,  1.1525e-02],\n",
      "          [ 5.6151e-02, -1.3285e-02, -7.1971e-03],\n",
      "          [ 1.1242e-03, -4.7446e-02, -3.6017e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5633e-02, -8.5117e-03,  6.2245e-02],\n",
      "          [ 1.0972e-02,  1.9737e-02,  4.8234e-02],\n",
      "          [-1.1555e-02,  4.3559e-03,  5.2946e-02]],\n",
      "\n",
      "         [[-1.0731e-03,  2.2912e-02,  2.2005e-02],\n",
      "          [ 1.3288e-02,  4.9365e-02,  1.2220e-02],\n",
      "          [ 1.0511e-02,  1.7318e-02, -1.8007e-02]],\n",
      "\n",
      "         [[-2.6693e-02, -1.8063e-02, -2.4829e-02],\n",
      "          [-3.3943e-02, -1.4893e-03, -1.1168e-02],\n",
      "          [-1.3225e-02, -4.6098e-03,  3.0331e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0866e-03, -2.5078e-02, -4.7683e-02],\n",
      "          [ 2.4006e-02,  5.2576e-02, -2.1802e-02],\n",
      "          [ 2.5606e-02,  1.1889e-02, -2.4519e-03]],\n",
      "\n",
      "         [[ 2.5286e-02, -2.8539e-02,  8.4982e-03],\n",
      "          [ 6.8764e-03, -8.9434e-03,  3.4527e-03],\n",
      "          [ 2.7720e-02,  1.2911e-02,  1.2079e-02]],\n",
      "\n",
      "         [[ 2.8175e-02,  1.3563e-02,  6.9976e-02],\n",
      "          [ 2.7799e-02, -3.6929e-02,  1.0927e-01],\n",
      "          [ 2.3212e-02, -3.4578e-02, -4.8821e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3232e-04,  1.7463e-02, -9.6818e-03],\n",
      "          [ 9.2093e-03,  1.5052e-02,  8.6647e-03],\n",
      "          [-1.8870e-02, -2.1472e-02, -1.5119e-02]],\n",
      "\n",
      "         [[ 4.3916e-02, -5.5188e-05, -7.7297e-03],\n",
      "          [-8.0442e-03, -3.4422e-02, -2.2207e-02],\n",
      "          [-1.4105e-02, -2.7909e-02, -2.4631e-02]],\n",
      "\n",
      "         [[-2.6292e-02,  1.1666e-02, -1.6261e-02],\n",
      "          [-5.7774e-02, -5.8361e-02, -4.8310e-02],\n",
      "          [-4.1695e-02, -6.6255e-02, -5.7636e-02]]]], requires_grad=True)\n",
      "name = features.6.bias param = Parameter containing:\n",
      "tensor([ 2.5296e-02,  1.1945e-01, -3.3357e-01,  1.1266e-01, -1.1582e-01,\n",
      "        -5.9723e-02,  1.1421e-01, -9.5083e-02,  3.1485e-02, -1.1093e-02,\n",
      "        -4.9384e-02,  9.1009e-02, -5.2086e-02,  3.6598e-02, -1.2018e-01,\n",
      "        -1.3416e-01, -5.0457e-03, -1.4378e-03, -7.6294e-02, -4.9133e-02,\n",
      "        -1.2550e-01,  2.3369e-01, -8.1535e-02,  2.4502e-02, -1.1238e-02,\n",
      "         1.3240e-01,  2.5781e-01, -2.4450e-02,  7.3169e-02,  2.0816e-01,\n",
      "         5.9903e-02, -1.1075e-02,  7.0557e-02,  5.3707e-03,  1.3942e-02,\n",
      "        -6.9005e-02,  9.5581e-02,  8.2127e-02, -8.9249e-02,  2.3552e-02,\n",
      "         2.0885e-02,  2.0952e-01,  5.7000e-02,  1.0061e-01, -1.5167e-01,\n",
      "         5.1431e-02,  6.0977e-02,  1.6120e-01,  4.6385e-02, -2.9361e-01,\n",
      "        -1.9220e-01, -3.3040e-02, -2.2844e-01,  5.2254e-02, -4.1985e-02,\n",
      "        -2.2856e-01, -2.2374e-01, -1.0398e-01, -3.9473e-02,  2.3086e-02,\n",
      "         8.5222e-02, -3.7522e-03,  9.9965e-02,  2.2243e-01,  1.4045e-01,\n",
      "        -8.3344e-02, -1.5321e-02,  8.4639e-04,  2.0019e-02, -1.4662e-01,\n",
      "        -5.2505e-02, -8.1782e-02,  3.8130e-01, -3.4659e-02, -4.2694e-02,\n",
      "         1.8965e-02,  3.0156e-01,  1.2823e-01,  1.3799e-01,  1.2063e-01,\n",
      "        -3.4695e-02,  1.0009e-01, -7.9640e-02, -7.5065e-02,  1.0233e-01,\n",
      "         3.2208e-01,  2.1217e-01,  3.0716e-01, -8.1736e-03,  1.3200e-01,\n",
      "        -6.8293e-02,  1.4088e-01, -6.3016e-02, -8.2268e-02,  3.3019e-02,\n",
      "        -1.8908e-01, -1.6634e-02, -1.8369e-01,  2.0020e-01,  6.9814e-02,\n",
      "        -1.3038e-02,  1.3110e-01,  1.9347e-01,  3.4634e-01, -4.2031e-02,\n",
      "        -1.6328e-02,  1.1963e-01, -6.8291e-02, -1.5022e-01,  9.9076e-03,\n",
      "        -3.0987e-01,  9.0031e-02, -8.1147e-02, -5.2415e-02, -9.0178e-02,\n",
      "         5.0669e-02, -2.6872e-02,  1.4879e-01, -6.0823e-02, -7.0688e-02,\n",
      "        -3.4375e-02,  1.9965e-01,  5.5266e-01, -7.1537e-02, -9.4906e-03,\n",
      "         1.0071e-01, -9.5097e-03, -2.5680e-02,  9.7761e-02,  1.1309e-02,\n",
      "         5.2728e-01,  2.7153e-01,  1.3556e-01,  2.2964e-01, -1.2627e-01,\n",
      "         1.3784e-02, -2.2356e-02, -1.8921e-01, -4.5453e-02, -2.9798e-02,\n",
      "         4.6675e-02, -5.1737e-02, -1.7543e-01, -3.4338e-01, -5.7257e-03,\n",
      "        -2.3548e-01,  5.3668e-02,  3.4909e-01, -2.3416e-01, -1.1250e-01,\n",
      "         3.1410e-02, -9.6694e-02, -1.6565e-01, -2.2653e-03, -2.5939e-01,\n",
      "         5.0781e-02,  8.9765e-02, -1.0748e-02,  1.2842e-01,  3.5524e-02,\n",
      "         3.3868e-02, -5.5422e-03, -9.5143e-02, -3.0961e-02,  3.2034e-02,\n",
      "         5.2717e-02,  1.2630e-01,  1.5936e-01,  3.5871e-02,  3.5311e-02,\n",
      "         3.6975e-01,  1.7943e-02, -2.2763e-02, -9.5617e-02,  1.7291e-01,\n",
      "         5.1715e-02,  1.5322e-01, -1.2241e-02,  2.5096e-01, -1.6052e-02,\n",
      "         2.2399e-02, -2.8640e-02,  1.1971e-01, -2.5529e-02, -4.1908e-02,\n",
      "         2.1012e-01, -1.3480e-01, -1.6478e-01, -2.5691e-02, -1.2916e-01,\n",
      "        -1.6463e-01,  5.3876e-02,  1.1469e-01, -1.1934e-01, -5.9146e-02,\n",
      "        -1.5055e-01, -2.7029e-02,  1.0714e-01, -8.8103e-02,  1.1475e-01,\n",
      "         1.7447e-01,  1.5797e-01,  5.2465e-02, -2.8796e-02,  2.4430e-01,\n",
      "         1.4584e-01,  1.1052e-02,  2.1882e-01,  3.9874e-01,  3.2079e-01,\n",
      "        -8.7249e-02, -7.7314e-02,  5.5055e-02, -7.4239e-02,  2.9941e-01,\n",
      "        -1.1196e-01,  2.0385e-02, -1.6533e-01, -8.4008e-02,  9.1928e-02,\n",
      "        -1.6281e-02, -1.3456e-02,  3.4111e-02, -1.5228e-01,  7.9972e-02,\n",
      "        -1.5468e-02,  9.0530e-02, -1.2425e-01,  4.0860e-02,  6.5097e-02,\n",
      "        -3.7378e-02, -2.5349e-02,  2.8863e-01, -1.7786e-01,  4.5379e-02,\n",
      "         8.0375e-02, -1.1857e-01,  1.2685e-01,  1.3253e-02,  4.4984e-03,\n",
      "         8.3759e-02,  1.5047e-01, -7.4856e-02, -5.1144e-02, -1.5849e-01,\n",
      "         1.1111e-01,  2.0428e-02,  1.9939e-02,  2.4965e-01,  2.1343e-01,\n",
      "         1.1922e-01,  1.5213e-01,  1.0119e-01, -2.0210e-02,  1.8933e-02,\n",
      "        -1.5583e-01,  2.6090e-01, -2.9025e-02,  6.5378e-02,  9.3637e-02,\n",
      "        -3.3498e-02, -1.0445e-01,  1.4307e-01,  8.0963e-02, -1.6300e-01,\n",
      "         1.8334e-01, -6.3191e-02,  3.4443e-02,  2.2093e-02, -1.0206e-01,\n",
      "         8.7264e-02,  1.8751e-02, -1.5014e-01,  2.3940e-01,  2.2395e-01,\n",
      "        -2.4017e-02,  2.3110e-01, -1.0960e-01, -1.6953e-01, -3.6366e-02,\n",
      "        -5.0821e-02,  7.6745e-02,  2.0642e-01,  1.4263e-03,  1.1277e-01,\n",
      "        -2.0354e-01,  8.0649e-02,  2.0421e-01,  3.6917e-01,  1.2266e-01,\n",
      "        -2.3815e-02, -7.3110e-02, -1.5845e-02,  1.2772e-01, -5.7867e-02,\n",
      "         2.8672e-01, -4.2656e-03, -2.1363e-05,  2.1605e-01,  1.5520e-01,\n",
      "        -1.6205e-02, -9.7204e-02, -1.0046e-01, -1.9993e-02, -1.5217e-01,\n",
      "        -5.9612e-02,  3.1248e-03, -3.4129e-01,  1.6236e-01,  1.7470e-01,\n",
      "         2.0988e-01, -6.3615e-02,  5.4698e-02, -2.4567e-01,  1.2553e-01,\n",
      "        -4.4876e-02, -5.9439e-02,  2.9393e-02,  1.5098e-01, -4.0008e-02,\n",
      "         1.1208e-01, -1.5519e-01,  5.0468e-01, -4.7305e-02, -7.5279e-02,\n",
      "         4.2626e-02, -1.3383e-01, -4.2012e-01,  3.8201e-01,  8.9413e-02,\n",
      "         5.3007e-02,  5.8240e-02,  4.2868e-02,  2.5090e-02,  1.9713e-01,\n",
      "         1.0120e-01, -1.1193e-01, -2.8088e-02,  3.5423e-01,  2.3811e-02,\n",
      "         1.2284e-01, -1.2416e-01,  3.0930e-02, -1.1544e-01, -2.8152e-02,\n",
      "         2.3655e-02,  1.5912e-02,  1.0024e-01,  1.1166e-01,  8.4823e-03,\n",
      "        -1.3086e-01,  9.2488e-02, -5.3630e-03,  8.9322e-02,  5.3354e-02,\n",
      "         6.6519e-02,  3.5378e-02,  4.4817e-02, -8.7586e-02,  1.3602e-01,\n",
      "         1.8784e-01, -3.7431e-02,  3.4593e-02,  3.8587e-02, -1.9506e-01,\n",
      "        -8.4326e-02, -6.7575e-02, -1.1365e-02,  1.0826e-01, -1.0933e-01,\n",
      "        -4.5308e-02,  2.1318e-02,  1.2107e-01,  1.1220e-01, -9.5198e-02,\n",
      "         5.0955e-01, -3.2508e-03,  5.4857e-02,  6.7155e-02,  1.0905e-01,\n",
      "         1.8573e-02, -2.9313e-02,  1.1019e-02, -1.1489e-02],\n",
      "       requires_grad=True)\n",
      "name = features.8.weight param = Parameter containing:\n",
      "tensor([[[[-0.0020, -0.0081, -0.0114],\n",
      "          [-0.0193,  0.0007,  0.0114],\n",
      "          [-0.0541, -0.0012, -0.0244]],\n",
      "\n",
      "         [[ 0.0350,  0.0133,  0.0260],\n",
      "          [-0.0282, -0.0062, -0.0269],\n",
      "          [ 0.0035,  0.0181,  0.0147]],\n",
      "\n",
      "         [[-0.0572, -0.0474,  0.0019],\n",
      "          [-0.0402, -0.0462, -0.0257],\n",
      "          [-0.0515, -0.0490,  0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0184, -0.0234,  0.0097],\n",
      "          [-0.0443, -0.0076, -0.0178],\n",
      "          [-0.0518, -0.0351, -0.0455]],\n",
      "\n",
      "         [[-0.0037, -0.0011, -0.0447],\n",
      "          [-0.0524, -0.0318, -0.0524],\n",
      "          [-0.0031, -0.0111, -0.0443]],\n",
      "\n",
      "         [[-0.0199, -0.0015,  0.0159],\n",
      "          [ 0.0051, -0.0149, -0.0237],\n",
      "          [ 0.0259,  0.0332,  0.0081]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0210,  0.0214,  0.0528],\n",
      "          [-0.0056,  0.0240,  0.0338],\n",
      "          [-0.0091,  0.0343,  0.0236]],\n",
      "\n",
      "         [[-0.0239, -0.0183, -0.0083],\n",
      "          [ 0.0316,  0.0136,  0.0453],\n",
      "          [-0.0357,  0.0247,  0.0101]],\n",
      "\n",
      "         [[ 0.0013,  0.0397,  0.0254],\n",
      "          [ 0.0308,  0.0113, -0.0031],\n",
      "          [-0.0280,  0.0023, -0.0184]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195, -0.0042, -0.0179],\n",
      "          [ 0.0192,  0.0265,  0.0026],\n",
      "          [ 0.0137, -0.0102,  0.0086]],\n",
      "\n",
      "         [[ 0.0275,  0.0256,  0.0252],\n",
      "          [-0.0102, -0.0263, -0.0122],\n",
      "          [-0.0340,  0.0067,  0.0385]],\n",
      "\n",
      "         [[-0.0022,  0.0217,  0.0112],\n",
      "          [ 0.0122, -0.0210,  0.0075],\n",
      "          [-0.0028, -0.0052, -0.0128]]],\n",
      "\n",
      "\n",
      "        [[[-0.0329, -0.0248, -0.0185],\n",
      "          [-0.0054,  0.0061,  0.0126],\n",
      "          [ 0.0478,  0.0188,  0.0413]],\n",
      "\n",
      "         [[-0.0074, -0.0016,  0.0026],\n",
      "          [ 0.0047, -0.0048,  0.0078],\n",
      "          [-0.0068,  0.0028,  0.0143]],\n",
      "\n",
      "         [[ 0.0005, -0.0228, -0.0027],\n",
      "          [-0.0152, -0.0249,  0.0235],\n",
      "          [ 0.0053, -0.0205,  0.0647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0352, -0.0149,  0.0171],\n",
      "          [-0.0023, -0.0084, -0.0010],\n",
      "          [-0.0209,  0.0037, -0.0223]],\n",
      "\n",
      "         [[-0.0042, -0.0047, -0.0100],\n",
      "          [-0.0069, -0.0281, -0.0387],\n",
      "          [ 0.0048,  0.0333,  0.0114]],\n",
      "\n",
      "         [[-0.0421,  0.0002, -0.0347],\n",
      "          [-0.0001,  0.0014, -0.0092],\n",
      "          [ 0.0719,  0.0502,  0.0573]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0410,  0.0385,  0.0163],\n",
      "          [ 0.0073, -0.0176, -0.0462],\n",
      "          [-0.0201, -0.0263, -0.0473]],\n",
      "\n",
      "         [[ 0.0129,  0.0227,  0.0252],\n",
      "          [ 0.0145,  0.0254,  0.0300],\n",
      "          [-0.0025,  0.0151,  0.0112]],\n",
      "\n",
      "         [[-0.0199, -0.0113, -0.0104],\n",
      "          [ 0.0127,  0.0129,  0.0073],\n",
      "          [ 0.0161,  0.0055, -0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0302,  0.0051, -0.0012],\n",
      "          [ 0.0208,  0.0003, -0.0187],\n",
      "          [-0.0144, -0.0357, -0.0175]],\n",
      "\n",
      "         [[ 0.0599,  0.0085,  0.0075],\n",
      "          [ 0.0610,  0.0170, -0.0337],\n",
      "          [ 0.0119,  0.0251, -0.0149]],\n",
      "\n",
      "         [[-0.0455, -0.0504, -0.0410],\n",
      "          [-0.0200, -0.0281, -0.0193],\n",
      "          [-0.0178, -0.0225, -0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0077, -0.0249,  0.0156],\n",
      "          [-0.0249,  0.0043,  0.0494],\n",
      "          [ 0.0045,  0.0455,  0.0455]],\n",
      "\n",
      "         [[ 0.0105,  0.0247, -0.0057],\n",
      "          [ 0.0461,  0.0305,  0.0349],\n",
      "          [-0.0354,  0.0422, -0.0025]],\n",
      "\n",
      "         [[ 0.0247,  0.0364,  0.0006],\n",
      "          [-0.0022, -0.0204, -0.0010],\n",
      "          [-0.0189, -0.0207, -0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0123, -0.0342, -0.0004],\n",
      "          [-0.0067, -0.0245, -0.0082],\n",
      "          [-0.0122,  0.0133,  0.0139]],\n",
      "\n",
      "         [[ 0.0098,  0.0259,  0.0180],\n",
      "          [ 0.0376,  0.0472,  0.0034],\n",
      "          [ 0.0239, -0.0019, -0.0128]],\n",
      "\n",
      "         [[ 0.0087,  0.0292, -0.0075],\n",
      "          [ 0.0031, -0.0118, -0.0158],\n",
      "          [-0.0128, -0.0524,  0.0036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0005,  0.0481,  0.0279],\n",
      "          [ 0.0006, -0.0294, -0.0090],\n",
      "          [ 0.0095,  0.0028,  0.0157]],\n",
      "\n",
      "         [[ 0.0166,  0.0328,  0.0182],\n",
      "          [-0.0055,  0.0275,  0.0119],\n",
      "          [-0.0541, -0.0190, -0.0386]],\n",
      "\n",
      "         [[-0.0386, -0.0353,  0.0143],\n",
      "          [-0.0577, -0.0483,  0.0289],\n",
      "          [-0.0361,  0.0032,  0.0618]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133,  0.0259,  0.0499],\n",
      "          [ 0.0033, -0.0500,  0.0009],\n",
      "          [ 0.0153,  0.0184,  0.0001]],\n",
      "\n",
      "         [[-0.0324, -0.0163,  0.0237],\n",
      "          [-0.0012, -0.0137,  0.0037],\n",
      "          [-0.0236,  0.0041,  0.0363]],\n",
      "\n",
      "         [[-0.0293, -0.0176, -0.0268],\n",
      "          [-0.0341,  0.0460, -0.0113],\n",
      "          [ 0.0003,  0.0701,  0.0068]]]], requires_grad=True)\n",
      "name = features.8.bias param = Parameter containing:\n",
      "tensor([-6.2908e-02,  1.2599e-01,  2.9910e-01,  1.1226e-01,  2.8529e-01,\n",
      "         1.2800e-01,  1.8281e-01, -3.0966e-02,  5.4521e-01,  1.5652e-01,\n",
      "        -1.3417e-01, -1.7108e-01,  2.7399e-01,  2.2774e-01,  2.6715e-01,\n",
      "         2.6192e-01,  4.5637e-02, -1.4264e+00,  6.0950e-01,  8.2353e-02,\n",
      "         9.6382e-02,  1.5679e-01, -2.9053e-01,  1.2642e-01,  2.0995e-01,\n",
      "         7.2459e-02, -2.7236e-04, -2.2086e-01,  1.1173e-01,  4.8032e-01,\n",
      "         3.5515e-02, -2.7491e-01, -5.0275e-01,  6.9615e-04, -1.2266e-01,\n",
      "         1.4878e-01, -8.2103e-03,  1.3206e-01,  2.9920e-01, -1.6474e-01,\n",
      "         3.2465e-01,  5.3489e-01,  2.4496e-01,  5.9936e-01,  3.3782e-02,\n",
      "         6.6390e-02,  4.8976e-01,  4.2106e-01,  6.3466e-01, -9.4680e-02,\n",
      "        -7.8501e-02,  2.5697e-01,  7.6671e-02, -2.3927e-01,  1.7104e-01,\n",
      "         4.1678e-01,  2.6976e-01, -4.6004e-01, -8.4528e-02,  2.7783e-01,\n",
      "         2.6750e-01,  3.3215e-01,  5.0680e-02, -8.6297e-02, -2.1007e-01,\n",
      "        -5.2222e-02, -4.1103e-02, -1.3916e-01, -3.0490e-01,  3.0167e-01,\n",
      "         2.3581e-01, -3.8736e-01, -6.0125e-02,  9.0375e-01, -1.4004e-01,\n",
      "         5.3197e-01,  2.3184e-01,  2.0689e-01,  2.3384e-01, -3.6393e-01,\n",
      "         2.2036e-01, -5.4082e-01, -6.4925e-01,  9.8469e-02,  3.4030e-01,\n",
      "         2.8475e-01, -1.1668e-01, -1.4938e-01,  2.6740e-01, -1.4695e-01,\n",
      "         5.2876e-02,  2.9656e-01,  1.4841e-02,  1.7320e-01,  1.5211e-01,\n",
      "         1.1128e-02, -2.4402e-02, -9.2617e-02, -5.4720e-02,  1.7771e-01,\n",
      "         7.6462e-03, -1.5598e-02, -1.9971e-02,  3.0060e-02,  3.4280e-01,\n",
      "         1.8484e-01, -1.8930e-01,  1.1917e-01,  4.3845e-02,  2.4088e-01,\n",
      "        -1.2948e-01,  2.8659e-01, -3.3983e-01,  1.7242e-01, -1.3951e-02,\n",
      "        -3.3238e-02, -2.1374e-01, -3.9050e-01,  6.9830e-01,  2.8698e-02,\n",
      "         7.4814e-02,  1.5877e-01,  1.6203e-01,  3.8714e-02,  1.4981e-01,\n",
      "        -7.0573e-02,  2.8210e-01,  3.0193e-01, -4.7925e-01,  9.4767e-02,\n",
      "        -2.5825e-01, -3.0498e-01,  3.7155e-01,  4.2541e-02,  2.2962e-01,\n",
      "         7.1776e-02,  1.0767e-01,  2.1197e-01,  2.8018e-01,  3.7508e-01,\n",
      "        -1.2975e-01,  2.2353e-01,  1.5561e-02,  2.9895e-01,  5.8271e-01,\n",
      "         4.4767e-01,  3.1934e-01,  1.5509e-01,  1.6081e-01,  2.4762e-01,\n",
      "        -6.7093e-01,  2.4884e-01,  1.4737e-01,  9.3295e-02,  2.3992e-01,\n",
      "        -2.5363e-01, -5.8247e-02,  2.2408e-01,  1.5920e-01, -5.6825e-02,\n",
      "         4.6530e-01, -2.1166e-01, -3.1839e-01, -1.2303e+00,  1.2068e-01,\n",
      "        -1.0088e-02,  3.3144e-01,  8.8529e-01, -5.0530e-02,  4.0095e-01,\n",
      "        -1.2923e-01, -6.6521e-02,  2.6929e-01,  2.9677e-01, -5.1512e-01,\n",
      "        -1.3941e-01,  3.3986e-02,  5.0526e-01,  2.3880e-01,  9.0405e-02,\n",
      "         2.8605e-01, -5.3700e-02, -2.3043e-01, -6.9528e-02,  6.2750e-02,\n",
      "        -8.3527e-02, -1.4610e-01,  1.8069e-01, -1.7798e-01, -9.7765e-02,\n",
      "        -6.4475e-03,  8.1148e-01,  2.0052e-01,  3.0710e-01, -2.3601e-01,\n",
      "         7.3178e-02,  1.1172e-01,  2.8366e-01,  6.6962e-02,  1.6107e-01,\n",
      "        -6.7723e-01,  1.3817e-01,  1.7344e-01, -4.4210e-02, -2.5060e-01,\n",
      "        -2.6521e-01,  1.6725e-01, -1.6838e-01, -8.5105e-02,  1.2462e-01,\n",
      "         4.2133e-02,  1.0998e-01,  4.3315e-01,  1.4762e-01, -2.2403e-02,\n",
      "         2.1770e-01,  5.9078e-02,  2.9927e-01,  8.4790e-02, -2.8061e-01,\n",
      "         3.7362e-02, -1.9944e-01, -4.8672e-01,  2.0394e-01,  1.9824e-01,\n",
      "         1.3828e-01,  3.0206e-02, -2.0721e-01,  7.0921e-01, -1.0912e-01,\n",
      "         4.8155e-01,  2.9200e-01,  4.7852e-02, -7.9537e-01, -4.4115e-02,\n",
      "         1.3331e-01, -1.9617e-01,  3.3779e-01,  4.0620e-01, -1.1334e-01,\n",
      "         5.1684e-02,  7.7361e-02,  2.6791e-01,  3.2820e-01,  1.8926e-01,\n",
      "        -2.1592e-02,  5.3141e-02, -2.4303e-01,  1.5920e-01,  5.7491e-01,\n",
      "         7.7323e-02, -7.1903e-03,  3.1149e-01,  3.3197e-02,  2.7632e-01,\n",
      "         1.4343e-01], requires_grad=True)\n",
      "name = features.10.weight param = Parameter containing:\n",
      "tensor([[[[ 4.5008e-03, -7.7347e-03, -1.5003e-02],\n",
      "          [-3.0285e-02, -4.4114e-02, -1.7563e-02],\n",
      "          [-1.4331e-02, -3.6714e-02, -5.2003e-02]],\n",
      "\n",
      "         [[ 3.3324e-02,  9.8262e-03, -6.4676e-03],\n",
      "          [ 1.4188e-02,  2.4336e-02,  3.1040e-02],\n",
      "          [-1.9439e-02,  1.9590e-02, -1.6543e-02]],\n",
      "\n",
      "         [[ 3.3328e-05, -6.3628e-04,  1.5421e-02],\n",
      "          [ 1.1260e-02,  5.7387e-04,  1.7457e-02],\n",
      "          [ 7.1211e-03,  1.0711e-03,  2.1856e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6804e-02, -2.1512e-02, -1.0703e-02],\n",
      "          [-1.0698e-02, -5.3842e-02, -1.9335e-02],\n",
      "          [ 1.6292e-02,  4.4939e-04,  6.5307e-05]],\n",
      "\n",
      "         [[ 1.2114e-03,  1.1926e-03, -1.7091e-03],\n",
      "          [-1.7243e-02, -2.7680e-02,  1.9918e-05],\n",
      "          [ 5.2268e-04, -1.6247e-03, -4.3989e-03]],\n",
      "\n",
      "         [[ 1.9892e-02,  2.9338e-02,  2.0883e-02],\n",
      "          [ 1.3522e-02,  3.1604e-02,  1.2854e-02],\n",
      "          [ 5.2760e-03,  1.2341e-02,  7.5441e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4208e-02,  2.3224e-03, -2.5112e-02],\n",
      "          [-7.6076e-03,  9.4883e-03, -4.6517e-03],\n",
      "          [ 1.3253e-02,  1.1511e-02, -1.4017e-02]],\n",
      "\n",
      "         [[ 2.1794e-02,  1.0763e-02,  1.1629e-02],\n",
      "          [ 4.1082e-02, -7.8142e-03,  1.9052e-02],\n",
      "          [ 6.6561e-02,  3.6654e-02,  2.0193e-03]],\n",
      "\n",
      "         [[-1.8703e-02, -4.9244e-02, -2.9182e-02],\n",
      "          [-1.5992e-02,  1.6744e-04,  4.5855e-03],\n",
      "          [-6.2261e-03,  4.1283e-03,  8.5156e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8011e-02, -7.3355e-02, -6.5635e-02],\n",
      "          [-5.9603e-02, -5.7514e-02, -4.2397e-02],\n",
      "          [-5.5825e-02, -6.3877e-02, -6.0623e-02]],\n",
      "\n",
      "         [[-3.6692e-02, -3.2975e-02, -1.0278e-02],\n",
      "          [-3.1835e-02, -5.3899e-03, -3.2266e-02],\n",
      "          [-3.2715e-02, -3.3150e-02, -2.8616e-02]],\n",
      "\n",
      "         [[-8.2592e-03, -2.5406e-02, -1.7791e-02],\n",
      "          [-1.1399e-02, -2.3384e-02, -1.1688e-02],\n",
      "          [-2.2682e-02, -3.1900e-02, -7.9640e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8231e-02, -2.9938e-02, -3.0918e-02],\n",
      "          [ 6.0674e-04, -4.5208e-02, -4.3832e-03],\n",
      "          [-6.0434e-03, -6.1846e-02, -1.4543e-02]],\n",
      "\n",
      "         [[ 1.3111e-02,  1.5979e-02, -5.2871e-03],\n",
      "          [-1.2694e-02,  1.2434e-03,  2.2471e-02],\n",
      "          [ 2.1080e-02, -6.7459e-03,  1.9622e-02]],\n",
      "\n",
      "         [[ 3.0896e-02, -3.0819e-02,  5.1553e-03],\n",
      "          [-5.7161e-04, -1.2514e-02,  2.3466e-02],\n",
      "          [ 2.5366e-02,  3.1077e-02,  2.8808e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0043e-02, -3.3691e-02, -3.3587e-02],\n",
      "          [-3.1222e-02, -4.3832e-02, -2.9784e-02],\n",
      "          [-5.5385e-02, -6.6676e-02, -5.1232e-02]],\n",
      "\n",
      "         [[-1.8431e-02, -1.0482e-02, -1.3102e-02],\n",
      "          [ 5.6541e-03, -2.6609e-02,  2.4034e-03],\n",
      "          [-2.3949e-02,  8.9346e-03,  3.3861e-03]],\n",
      "\n",
      "         [[ 5.7008e-03, -1.4837e-02,  1.3501e-03],\n",
      "          [-5.6762e-04,  6.3385e-03,  5.1770e-03],\n",
      "          [ 5.5514e-03, -1.4905e-03, -2.3526e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8694e-02, -5.8550e-03,  7.5898e-03],\n",
      "          [ 5.4762e-03, -5.1852e-02,  5.3048e-03],\n",
      "          [ 5.4274e-02, -3.1494e-03, -5.8523e-03]],\n",
      "\n",
      "         [[ 1.0686e-02, -1.6323e-02,  2.0675e-02],\n",
      "          [ 1.9367e-03, -3.2638e-02,  9.5754e-04],\n",
      "          [ 2.1652e-03,  2.7449e-02,  5.5060e-02]],\n",
      "\n",
      "         [[ 5.0755e-03, -2.6414e-02,  1.8585e-02],\n",
      "          [-2.5866e-03,  1.2334e-03,  4.8944e-03],\n",
      "          [ 5.3379e-04, -8.6257e-03, -2.3603e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3444e-02,  9.6432e-03,  1.7831e-02],\n",
      "          [-1.8331e-02, -5.7185e-02, -2.1030e-02],\n",
      "          [ 1.0187e-02, -3.0167e-02, -8.0193e-03]],\n",
      "\n",
      "         [[ 1.7629e-02,  2.5001e-02, -4.5713e-02],\n",
      "          [ 2.5250e-02,  3.9404e-02,  3.0033e-02],\n",
      "          [ 1.6265e-02,  5.3023e-02,  8.1163e-03]],\n",
      "\n",
      "         [[ 4.1792e-03,  8.5183e-03,  3.5242e-03],\n",
      "          [ 2.7552e-02,  4.5622e-02,  3.8444e-03],\n",
      "          [ 2.1285e-02,  2.0103e-02,  1.6193e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4135e-02, -3.3222e-02, -5.2931e-03],\n",
      "          [-8.9475e-03, -3.3265e-02,  4.3306e-03],\n",
      "          [ 1.7092e-02, -2.8524e-02, -2.5048e-02]],\n",
      "\n",
      "         [[-1.4275e-02, -2.7405e-02,  1.1635e-02],\n",
      "          [-2.2799e-02, -3.2017e-02, -9.8221e-03],\n",
      "          [-2.0387e-02, -3.1692e-02, -9.8188e-03]],\n",
      "\n",
      "         [[-2.0245e-02, -7.1923e-03,  5.0653e-03],\n",
      "          [ 9.2916e-03, -1.4393e-02, -2.8599e-02],\n",
      "          [ 1.5616e-03, -1.7386e-02, -7.2756e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4874e-02, -9.5781e-03,  2.7291e-02],\n",
      "          [ 1.7682e-03, -1.8440e-02,  7.5908e-03],\n",
      "          [-6.8078e-03, -1.3905e-03,  3.8714e-03]],\n",
      "\n",
      "         [[-2.7931e-02, -3.4299e-02, -1.5767e-02],\n",
      "          [-1.5908e-02, -4.4211e-02, -1.5330e-02],\n",
      "          [-1.9257e-02, -2.3017e-02,  7.2739e-04]],\n",
      "\n",
      "         [[-3.6868e-02,  1.5530e-02, -7.3656e-04],\n",
      "          [-3.2403e-03, -2.5565e-02, -6.2375e-04],\n",
      "          [-7.5825e-03, -1.7276e-02, -1.2110e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0703e-03, -3.1071e-02,  4.9807e-04],\n",
      "          [ 1.3618e-02,  6.6683e-03, -1.3059e-02],\n",
      "          [-1.5806e-02,  9.5659e-03, -2.8366e-02]],\n",
      "\n",
      "         [[-1.5622e-02,  1.0870e-02, -4.3911e-02],\n",
      "          [-6.0366e-03,  4.7041e-02, -6.7736e-03],\n",
      "          [ 2.3879e-02,  1.5275e-02,  2.1209e-02]],\n",
      "\n",
      "         [[-3.4367e-02, -2.7406e-03, -4.0337e-02],\n",
      "          [-2.1270e-02, -2.4037e-02, -2.0263e-02],\n",
      "          [-7.9488e-03, -1.4826e-03, -6.8217e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0063e-02, -2.2878e-02, -5.5036e-03],\n",
      "          [ 3.2441e-02, -1.3513e-02,  2.5942e-03],\n",
      "          [-2.8327e-02, -3.6309e-02, -1.9826e-02]],\n",
      "\n",
      "         [[-9.0379e-03,  1.6569e-02,  5.9027e-04],\n",
      "          [-7.4690e-04,  3.3369e-02,  2.2972e-02],\n",
      "          [ 1.0572e-02,  8.1467e-03, -3.4821e-02]],\n",
      "\n",
      "         [[ 7.4795e-03,  1.9532e-03,  8.9045e-03],\n",
      "          [-7.3107e-03, -2.9493e-02,  1.2008e-03],\n",
      "          [ 8.8704e-03,  1.1838e-02,  7.4983e-04]]]], requires_grad=True)\n",
      "name = features.10.bias param = Parameter containing:\n",
      "tensor([ 3.7964e-02,  4.3626e-01,  1.9919e-01,  4.7873e-01,  1.9452e-01,\n",
      "         4.6094e-02,  8.9556e-02, -9.0875e-02,  1.2068e-01,  1.8953e-01,\n",
      "         4.5016e-02,  4.8434e-01,  2.4634e-01, -7.8553e-02, -4.1008e-02,\n",
      "        -4.5605e-01,  6.7455e-01,  4.3669e-02, -3.8591e-01,  2.3154e-01,\n",
      "         1.2107e-01,  3.2227e-01,  1.1335e+00,  2.1153e-01,  4.7995e-01,\n",
      "         2.8958e-01,  6.4578e-02,  2.4041e-02,  1.5042e-01,  2.8817e-01,\n",
      "         6.7181e-02,  2.6940e-01,  1.0063e-02,  3.4250e-01,  1.6370e-01,\n",
      "         2.0520e-01,  7.5118e-02,  1.1070e-01,  2.6571e-01,  1.2281e-01,\n",
      "        -4.6485e-02,  5.1063e-01,  1.4461e-01,  4.4510e-01,  3.3639e-01,\n",
      "         4.0720e-01, -2.1050e-02,  1.1052e+00,  1.2309e-01,  3.1051e-01,\n",
      "         2.3018e-01,  3.6438e-01,  3.8058e-01,  1.7631e-01,  6.3093e-01,\n",
      "        -1.3756e-02,  2.6251e-01,  2.0362e-01,  3.4236e-01,  1.9062e-02,\n",
      "         1.5609e-01,  2.2937e-01, -8.7384e-02,  3.1602e-02,  8.6188e-02,\n",
      "         2.4748e-01, -7.8154e-03,  2.2365e-01,  2.4816e-01,  7.1836e-02,\n",
      "        -6.6000e-02, -6.8084e-02, -2.1012e-02,  4.0951e-01,  4.2487e-01,\n",
      "         3.0534e-01, -1.1383e-01,  2.4841e-02,  1.1446e-01,  7.3555e-03,\n",
      "        -4.6246e-02,  6.3487e-01, -1.1421e-01,  6.1986e-01,  9.2757e-02,\n",
      "        -1.4665e-02,  4.6250e-01,  6.3386e-01, -1.7848e-02,  1.3755e-01,\n",
      "         1.2155e-02,  1.9338e-01,  1.9085e-02,  8.1355e-02,  1.7102e-02,\n",
      "         4.4921e-02,  1.9130e-01,  2.0720e-01,  1.7913e-03,  4.5546e-01,\n",
      "         3.8208e-01,  3.2588e-01, -1.0084e-01,  5.0784e-01,  1.2523e-02,\n",
      "         5.9673e-01,  8.0652e-01,  4.6247e-01,  1.4344e-01,  9.7860e-03,\n",
      "        -3.8480e-02,  3.1713e-02,  1.3493e-01,  5.5403e-01,  1.3879e-01,\n",
      "         1.8507e-01,  3.5126e-02, -1.2923e-01,  1.5486e-01,  6.6569e-02,\n",
      "         2.2698e-01, -8.0724e-02,  5.2492e-01,  1.2118e-01,  2.5738e-02,\n",
      "         2.4021e+00,  5.4695e-01, -1.7379e-01,  1.0619e-01, -4.2293e-02,\n",
      "         3.7618e-02,  2.4259e-01, -7.6743e-02,  2.1944e-02,  4.8954e-01,\n",
      "         4.1475e-01,  4.8341e-02, -3.5894e-02,  1.4445e-01, -2.0989e-01,\n",
      "         2.6906e-01,  6.1454e-02,  4.7476e-03,  5.8720e-01,  2.1773e-01,\n",
      "         8.1851e-01,  4.1794e-01,  4.1514e-02,  1.7567e-01,  9.2828e-01,\n",
      "         1.3975e-01,  3.6809e-01,  6.7954e-01, -4.6613e-02,  6.1853e-01,\n",
      "         9.9139e-02,  3.7578e-01,  1.2078e-01,  7.3212e-01,  1.4217e-01,\n",
      "        -1.5891e-02,  4.9133e-01,  6.9460e-02,  1.6718e-01,  6.8328e-01,\n",
      "         3.6984e-01,  1.1704e-01,  4.6448e-03,  4.4395e-01,  1.6502e-01,\n",
      "         1.2848e-01,  2.1826e-01,  7.0516e-01,  4.1369e-03,  1.6124e-01,\n",
      "         1.1174e-01, -8.4453e-04,  2.6191e-01,  7.3103e-02,  2.6202e-01,\n",
      "         1.5253e-02,  2.0889e-01,  3.3991e-01,  3.9360e-02,  9.8699e-02,\n",
      "         2.8095e-01,  1.3300e-01, -9.8729e-02,  1.5865e-01, -1.0977e-01,\n",
      "        -1.2899e-01,  1.5089e-01,  1.3981e-01,  1.9367e-03,  1.0875e-01,\n",
      "        -1.6497e-01,  5.6130e-02,  1.7397e-01,  4.1817e-01,  1.1607e-01,\n",
      "         3.5296e-01,  8.5897e-01,  2.8839e-01,  1.1828e-01, -5.0673e-02,\n",
      "         2.8798e-02,  1.3510e-01,  1.9383e-01, -1.9312e-02,  5.4221e-01,\n",
      "         5.3677e-01,  4.4037e-01,  5.0655e-01,  3.5812e-01,  5.3000e-01,\n",
      "         5.1179e-01,  2.0096e-01,  3.6999e-01,  6.0126e-01,  4.2610e-03,\n",
      "         1.9014e-02, -1.7977e-01,  6.5511e-02,  6.4663e-01,  2.4109e-01,\n",
      "         1.3175e-01,  6.0788e-01, -4.4901e-03,  6.0372e-01,  2.9686e-01,\n",
      "         6.3624e-01,  3.3710e-01,  1.0049e-01,  4.1112e-01,  5.2909e-01,\n",
      "         1.8214e-01,  2.3342e-01,  3.5865e-02,  9.3808e-02,  1.6784e-01,\n",
      "         9.7704e-02,  4.3545e-01,  3.4650e-02, -7.2180e-02,  1.4837e-01,\n",
      "        -9.3362e-02,  4.1976e-01, -4.9194e-03,  1.8956e-01,  5.4447e-01,\n",
      "         5.3322e-01,  3.6115e-01,  3.2763e-01,  5.5909e-01,  2.0211e-03,\n",
      "        -6.6487e-02], requires_grad=True)\n",
      "name = classifier.1.weight param = Parameter containing:\n",
      "tensor([[-5.1409e-03,  2.0625e-04,  7.5108e-03,  ...,  4.3785e-03,\n",
      "         -4.1771e-03,  2.8104e-03],\n",
      "        [ 7.8974e-03,  4.2923e-03, -4.8754e-03,  ...,  6.8813e-03,\n",
      "          1.3510e-03,  5.3042e-03],\n",
      "        [-6.8330e-03, -6.2725e-04, -1.0610e-03,  ..., -1.0243e-02,\n",
      "         -6.4478e-03, -5.4473e-03],\n",
      "        ...,\n",
      "        [ 9.6883e-03,  1.0358e-02, -2.0524e-03,  ..., -3.3376e-03,\n",
      "          2.9722e-03,  4.6542e-03],\n",
      "        [-7.6864e-03,  1.6419e-03, -8.3548e-03,  ...,  2.0403e-03,\n",
      "          7.1420e-03,  9.4657e-05],\n",
      "        [ 4.1422e-03, -5.2020e-03,  4.6801e-03,  ..., -8.4280e-03,\n",
      "          7.3671e-03, -7.7646e-03]], requires_grad=True)\n",
      "name = classifier.1.bias param = Parameter containing:\n",
      "tensor([-0.0072, -0.0047, -0.0021,  ..., -0.0086, -0.0080, -0.0080],\n",
      "       requires_grad=True)\n",
      "name = classifier.4.weight param = Parameter containing:\n",
      "tensor([[ 0.0033,  0.0078, -0.0070,  ...,  0.0026, -0.0009, -0.0100],\n",
      "        [-0.0122,  0.0051,  0.0097,  ...,  0.0138, -0.0055, -0.0069],\n",
      "        [-0.0098,  0.0004, -0.0051,  ..., -0.0002,  0.0024, -0.0145],\n",
      "        ...,\n",
      "        [ 0.0008, -0.0042, -0.0100,  ...,  0.0122, -0.0010,  0.0046],\n",
      "        [ 0.0078,  0.0079, -0.0080,  ...,  0.0072, -0.0034, -0.0130],\n",
      "        [ 0.0022, -0.0076, -0.0046,  ..., -0.0012,  0.0059, -0.0102]],\n",
      "       requires_grad=True)\n",
      "name = classifier.4.bias param = Parameter containing:\n",
      "tensor([-0.0097,  0.0130, -0.0104,  ..., -0.0081, -0.0131,  0.0148],\n",
      "       requires_grad=True)\n",
      "name = classifier.5.weight param = Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "name = classifier.5.bias param = Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "name = classifier.7.weight param = Parameter containing:\n",
      "tensor([[ 0.0147, -0.0135,  0.0031,  ...,  0.0120,  0.0147,  0.0038],\n",
      "        [ 0.0137, -0.0014,  0.0153,  ..., -0.0142, -0.0023,  0.0022],\n",
      "        [ 0.0043,  0.0112, -0.0019,  ...,  0.0134, -0.0128,  0.0008],\n",
      "        ...,\n",
      "        [-0.0134, -0.0073, -0.0155,  ...,  0.0003,  0.0117, -0.0113],\n",
      "        [-0.0006,  0.0097, -0.0097,  ..., -0.0056,  0.0078, -0.0021],\n",
      "        [-0.0107, -0.0074,  0.0038,  ..., -0.0018, -0.0041,  0.0012]],\n",
      "       requires_grad=True)\n",
      "name = classifier.7.bias param = Parameter containing:\n",
      "tensor([-0.0106, -0.0023,  0.0057,  0.0069, -0.0137,  0.0035,  0.0047, -0.0054],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#freezing model layers\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "\n",
    "# for name, param in model.features.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "#     #print(\"name =\", name, \"param =\", param)\n",
    "    \n",
    "for name, param in model.named_parameters():\n",
    "    print(\"name =\", name, \"param =\", param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Linear(in_features=4096, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have multiple GPUs..\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"we have multiple GPUs..\")\n",
    "  model = nn.DataParallel(model)\n",
    "  \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TS9RPR4_ZtOe"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "YvtUdSabaWQE",
    "outputId": "99d0bb34-8d53-4d78-e2fd-cab63fe59fd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Train [0/14674 (0%)]\tLoss: 2.113259\n",
      "Train [3200/14674 (22%)]\tLoss: 1.630526\n",
      "Train [6400/14674 (43%)]\tLoss: 1.375086\n",
      "Train [9600/14674 (65%)]\tLoss: 0.766062\n",
      "Train [12800/14674 (87%)]\tLoss: 0.949130\n",
      "Train set: Average loss: 0.0195, Accuracy: 8140/14674 (55.47%)\n",
      "Validation set: Average loss: 0.0257, Accuracy: 706/1756 (40.21%)\n",
      "\n",
      "Epoch:  1\n",
      "Train [0/14674 (0%)]\tLoss: 0.852375\n",
      "Train [3200/14674 (22%)]\tLoss: 0.738416\n",
      "Train [6400/14674 (43%)]\tLoss: 0.736420\n",
      "Train [9600/14674 (65%)]\tLoss: 0.683621\n",
      "Train [12800/14674 (87%)]\tLoss: 0.545412\n",
      "Train set: Average loss: 0.0110, Accuracy: 11111/14674 (75.72%)\n",
      "Validation set: Average loss: 0.0239, Accuracy: 869/1756 (49.49%)\n",
      "\n",
      "Epoch:  2\n",
      "Train [0/14674 (0%)]\tLoss: 0.592573\n",
      "Train [3200/14674 (22%)]\tLoss: 0.623845\n",
      "Train [6400/14674 (43%)]\tLoss: 0.540011\n",
      "Train [9600/14674 (65%)]\tLoss: 0.522359\n",
      "Train [12800/14674 (87%)]\tLoss: 0.552697\n",
      "Train set: Average loss: 0.0085, Accuracy: 11946/14674 (81.41%)\n",
      "Validation set: Average loss: 0.0285, Accuracy: 752/1756 (42.82%)\n",
      "\n",
      "Epoch:  3\n",
      "Train [0/14674 (0%)]\tLoss: 0.533017\n",
      "Train [3200/14674 (22%)]\tLoss: 0.505508\n",
      "Train [6400/14674 (43%)]\tLoss: 0.455028\n",
      "Train [9600/14674 (65%)]\tLoss: 0.644661\n",
      "Train [12800/14674 (87%)]\tLoss: 0.366380\n",
      "Train set: Average loss: 0.0071, Accuracy: 12444/14674 (84.80%)\n",
      "Validation set: Average loss: 0.0243, Accuracy: 919/1756 (52.33%)\n",
      "\n",
      "Epoch:  4\n",
      "Train [0/14674 (0%)]\tLoss: 0.409036\n",
      "Train [3200/14674 (22%)]\tLoss: 0.342728\n",
      "Train [6400/14674 (43%)]\tLoss: 0.445958\n",
      "Train [9600/14674 (65%)]\tLoss: 0.282380\n",
      "Train [12800/14674 (87%)]\tLoss: 0.585064\n",
      "Train set: Average loss: 0.0058, Accuracy: 12814/14674 (87.32%)\n",
      "Validation set: Average loss: 0.0262, Accuracy: 844/1756 (48.06%)\n",
      "\n",
      "Epoch:  5\n",
      "Train [0/14674 (0%)]\tLoss: 0.174296\n",
      "Train [3200/14674 (22%)]\tLoss: 0.284121\n",
      "Train [6400/14674 (43%)]\tLoss: 0.459433\n",
      "Train [9600/14674 (65%)]\tLoss: 0.369339\n",
      "Train [12800/14674 (87%)]\tLoss: 0.267741\n",
      "Train set: Average loss: 0.0050, Accuracy: 13079/14674 (89.13%)\n",
      "Validation set: Average loss: 0.0306, Accuracy: 787/1756 (44.82%)\n",
      "\n",
      "Epoch:  6\n",
      "Train [0/14674 (0%)]\tLoss: 0.407798\n",
      "Train [3200/14674 (22%)]\tLoss: 0.278539\n",
      "Train [6400/14674 (43%)]\tLoss: 0.253174\n",
      "Train [9600/14674 (65%)]\tLoss: 0.219841\n",
      "Train [12800/14674 (87%)]\tLoss: 0.359513\n",
      "Train set: Average loss: 0.0044, Accuracy: 13226/14674 (90.13%)\n",
      "Validation set: Average loss: 0.0251, Accuracy: 902/1756 (51.37%)\n",
      "\n",
      "Epoch:  7\n",
      "Train [0/14674 (0%)]\tLoss: 0.186271\n",
      "Train [3200/14674 (22%)]\tLoss: 0.253728\n",
      "Train [6400/14674 (43%)]\tLoss: 0.277194\n",
      "Train [9600/14674 (65%)]\tLoss: 0.136644\n",
      "Train [12800/14674 (87%)]\tLoss: 0.097107\n",
      "Train set: Average loss: 0.0031, Accuracy: 13694/14674 (93.32%)\n",
      "Validation set: Average loss: 0.0240, Accuracy: 955/1756 (54.38%)\n",
      "\n",
      "Epoch:  8\n",
      "Train [0/14674 (0%)]\tLoss: 0.146327\n",
      "Train [3200/14674 (22%)]\tLoss: 0.192792\n",
      "Train [6400/14674 (43%)]\tLoss: 0.179655\n",
      "Train [9600/14674 (65%)]\tLoss: 0.094232\n",
      "Train [12800/14674 (87%)]\tLoss: 0.235142\n",
      "Train set: Average loss: 0.0027, Accuracy: 13817/14674 (94.16%)\n",
      "Validation set: Average loss: 0.0253, Accuracy: 907/1756 (51.65%)\n",
      "\n",
      "Epoch:  9\n",
      "Train [0/14674 (0%)]\tLoss: 0.179083\n",
      "Train [3200/14674 (22%)]\tLoss: 0.105554\n",
      "Train [6400/14674 (43%)]\tLoss: 0.118986\n",
      "Train [9600/14674 (65%)]\tLoss: 0.234740\n",
      "Train [12800/14674 (87%)]\tLoss: 0.098981\n",
      "Train set: Average loss: 0.0026, Accuracy: 13852/14674 (94.40%)\n",
      "Validation set: Average loss: 0.0257, Accuracy: 918/1756 (52.28%)\n",
      "\n",
      "Epoch:  10\n",
      "Train [0/14674 (0%)]\tLoss: 0.166958\n",
      "Train [3200/14674 (22%)]\tLoss: 0.141284\n",
      "Train [6400/14674 (43%)]\tLoss: 0.248581\n",
      "Train [9600/14674 (65%)]\tLoss: 0.112171\n",
      "Train [12800/14674 (87%)]\tLoss: 0.164557\n",
      "Train set: Average loss: 0.0024, Accuracy: 13950/14674 (95.07%)\n",
      "Validation set: Average loss: 0.0250, Accuracy: 945/1756 (53.82%)\n",
      "\n",
      "Epoch:  11\n",
      "Train [0/14674 (0%)]\tLoss: 0.199079\n",
      "Train [3200/14674 (22%)]\tLoss: 0.166110\n",
      "Train [6400/14674 (43%)]\tLoss: 0.147651\n",
      "Train [9600/14674 (65%)]\tLoss: 0.086821\n",
      "Train [12800/14674 (87%)]\tLoss: 0.272557\n",
      "Train set: Average loss: 0.0024, Accuracy: 13960/14674 (95.13%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 906/1756 (51.59%)\n",
      "\n",
      "Epoch:  12\n",
      "Train [0/14674 (0%)]\tLoss: 0.144897\n",
      "Train [3200/14674 (22%)]\tLoss: 0.121972\n",
      "Train [6400/14674 (43%)]\tLoss: 0.082637\n",
      "Train [9600/14674 (65%)]\tLoss: 0.207229\n",
      "Train [12800/14674 (87%)]\tLoss: 0.178854\n",
      "Train set: Average loss: 0.0024, Accuracy: 13944/14674 (95.03%)\n",
      "Validation set: Average loss: 0.0252, Accuracy: 914/1756 (52.05%)\n",
      "\n",
      "Epoch:  13\n",
      "Train [0/14674 (0%)]\tLoss: 0.101022\n",
      "Train [3200/14674 (22%)]\tLoss: 0.168018\n",
      "Train [6400/14674 (43%)]\tLoss: 0.053196\n",
      "Train [9600/14674 (65%)]\tLoss: 0.128910\n",
      "Train [12800/14674 (87%)]\tLoss: 0.102599\n",
      "Train set: Average loss: 0.0022, Accuracy: 14015/14674 (95.51%)\n",
      "Validation set: Average loss: 0.0265, Accuracy: 918/1756 (52.28%)\n",
      "\n",
      "Epoch:  14\n",
      "Train [0/14674 (0%)]\tLoss: 0.173183\n",
      "Train [3200/14674 (22%)]\tLoss: 0.197759\n",
      "Train [6400/14674 (43%)]\tLoss: 0.066560\n",
      "Train [9600/14674 (65%)]\tLoss: 0.075093\n",
      "Train [12800/14674 (87%)]\tLoss: 0.099248\n",
      "Train set: Average loss: 0.0022, Accuracy: 14029/14674 (95.60%)\n",
      "Validation set: Average loss: 0.0247, Accuracy: 962/1756 (54.78%)\n",
      "\n",
      "Epoch:  15\n",
      "Train [0/14674 (0%)]\tLoss: 0.116680\n",
      "Train [3200/14674 (22%)]\tLoss: 0.110476\n",
      "Train [6400/14674 (43%)]\tLoss: 0.131690\n",
      "Train [9600/14674 (65%)]\tLoss: 0.077302\n",
      "Train [12800/14674 (87%)]\tLoss: 0.096081\n",
      "Train set: Average loss: 0.0021, Accuracy: 14031/14674 (95.62%)\n",
      "Validation set: Average loss: 0.0261, Accuracy: 922/1756 (52.51%)\n",
      "\n",
      "Epoch:  16\n",
      "Train [0/14674 (0%)]\tLoss: 0.104490\n",
      "Train [3200/14674 (22%)]\tLoss: 0.171606\n",
      "Train [6400/14674 (43%)]\tLoss: 0.142203\n",
      "Train [9600/14674 (65%)]\tLoss: 0.086795\n",
      "Train [12800/14674 (87%)]\tLoss: 0.065972\n",
      "Train set: Average loss: 0.0021, Accuracy: 14032/14674 (95.62%)\n",
      "Validation set: Average loss: 0.0257, Accuracy: 948/1756 (53.99%)\n",
      "\n",
      "Epoch:  17\n",
      "Train [0/14674 (0%)]\tLoss: 0.170744\n",
      "Train [3200/14674 (22%)]\tLoss: 0.082936\n",
      "Train [6400/14674 (43%)]\tLoss: 0.064942\n",
      "Train [9600/14674 (65%)]\tLoss: 0.123795\n",
      "Train [12800/14674 (87%)]\tLoss: 0.075767\n",
      "Train set: Average loss: 0.0021, Accuracy: 13988/14674 (95.33%)\n",
      "Validation set: Average loss: 0.0255, Accuracy: 934/1756 (53.19%)\n",
      "\n",
      "Epoch:  18\n",
      "Train [0/14674 (0%)]\tLoss: 0.245461\n",
      "Train [3200/14674 (22%)]\tLoss: 0.189364\n",
      "Train [6400/14674 (43%)]\tLoss: 0.259495\n",
      "Train [9600/14674 (65%)]\tLoss: 0.067952\n",
      "Train [12800/14674 (87%)]\tLoss: 0.075514\n",
      "Train set: Average loss: 0.0020, Accuracy: 14065/14674 (95.85%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 942/1756 (53.64%)\n",
      "\n",
      "Epoch:  19\n",
      "Train [0/14674 (0%)]\tLoss: 0.099834\n",
      "Train [3200/14674 (22%)]\tLoss: 0.303519\n",
      "Train [6400/14674 (43%)]\tLoss: 0.193895\n",
      "Train [9600/14674 (65%)]\tLoss: 0.140282\n",
      "Train [12800/14674 (87%)]\tLoss: 0.147262\n",
      "Train set: Average loss: 0.0021, Accuracy: 14020/14674 (95.54%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 926/1756 (52.73%)\n",
      "\n",
      "Epoch:  20\n",
      "Train [0/14674 (0%)]\tLoss: 0.153310\n",
      "Train [3200/14674 (22%)]\tLoss: 0.125004\n",
      "Train [6400/14674 (43%)]\tLoss: 0.169476\n",
      "Train [9600/14674 (65%)]\tLoss: 0.054916\n",
      "Train [12800/14674 (87%)]\tLoss: 0.189088\n",
      "Train set: Average loss: 0.0021, Accuracy: 14051/14674 (95.75%)\n",
      "Validation set: Average loss: 0.0266, Accuracy: 904/1756 (51.48%)\n",
      "\n",
      "Epoch:  21\n",
      "Train [0/14674 (0%)]\tLoss: 0.046267\n",
      "Train [3200/14674 (22%)]\tLoss: 0.076246\n",
      "Train [6400/14674 (43%)]\tLoss: 0.065693\n",
      "Train [9600/14674 (65%)]\tLoss: 0.194699\n",
      "Train [12800/14674 (87%)]\tLoss: 0.100004\n",
      "Train set: Average loss: 0.0020, Accuracy: 14032/14674 (95.62%)\n",
      "Validation set: Average loss: 0.0260, Accuracy: 954/1756 (54.33%)\n",
      "\n",
      "Epoch:  22\n",
      "Train [0/14674 (0%)]\tLoss: 0.199747\n",
      "Train [3200/14674 (22%)]\tLoss: 0.232147\n",
      "Train [6400/14674 (43%)]\tLoss: 0.143793\n",
      "Train [9600/14674 (65%)]\tLoss: 0.124904\n",
      "Train [12800/14674 (87%)]\tLoss: 0.033515\n",
      "Train set: Average loss: 0.0022, Accuracy: 14015/14674 (95.51%)\n",
      "Validation set: Average loss: 0.0253, Accuracy: 962/1756 (54.78%)\n",
      "\n",
      "Epoch:  23\n",
      "Train [0/14674 (0%)]\tLoss: 0.152398\n",
      "Train [3200/14674 (22%)]\tLoss: 0.167825\n",
      "Train [6400/14674 (43%)]\tLoss: 0.141939\n",
      "Train [9600/14674 (65%)]\tLoss: 0.146755\n",
      "Train [12800/14674 (87%)]\tLoss: 0.106105\n",
      "Train set: Average loss: 0.0021, Accuracy: 14022/14674 (95.56%)\n",
      "Validation set: Average loss: 0.0260, Accuracy: 920/1756 (52.39%)\n",
      "\n",
      "Epoch:  24\n",
      "Train [0/14674 (0%)]\tLoss: 0.176460\n",
      "Train [3200/14674 (22%)]\tLoss: 0.170615\n",
      "Train [6400/14674 (43%)]\tLoss: 0.106444\n",
      "Train [9600/14674 (65%)]\tLoss: 0.119801\n",
      "Train [12800/14674 (87%)]\tLoss: 0.124853\n",
      "Train set: Average loss: 0.0021, Accuracy: 14015/14674 (95.51%)\n",
      "Validation set: Average loss: 0.0250, Accuracy: 972/1756 (55.35%)\n",
      "\n",
      "Epoch:  25\n",
      "Train [0/14674 (0%)]\tLoss: 0.138302\n",
      "Train [3200/14674 (22%)]\tLoss: 0.104343\n",
      "Train [6400/14674 (43%)]\tLoss: 0.150695\n",
      "Train [9600/14674 (65%)]\tLoss: 0.177954\n",
      "Train [12800/14674 (87%)]\tLoss: 0.167846\n",
      "Train set: Average loss: 0.0021, Accuracy: 14064/14674 (95.84%)\n",
      "Validation set: Average loss: 0.0264, Accuracy: 930/1756 (52.96%)\n",
      "\n",
      "Epoch:  26\n",
      "Train [0/14674 (0%)]\tLoss: 0.075135\n",
      "Train [3200/14674 (22%)]\tLoss: 0.072543\n",
      "Train [6400/14674 (43%)]\tLoss: 0.197865\n",
      "Train [9600/14674 (65%)]\tLoss: 0.067199\n",
      "Train [12800/14674 (87%)]\tLoss: 0.128413\n",
      "Train set: Average loss: 0.0021, Accuracy: 14001/14674 (95.41%)\n",
      "Validation set: Average loss: 0.0266, Accuracy: 923/1756 (52.56%)\n",
      "\n",
      "Epoch:  27\n",
      "Train [0/14674 (0%)]\tLoss: 0.153049\n",
      "Train [3200/14674 (22%)]\tLoss: 0.074294\n",
      "Train [6400/14674 (43%)]\tLoss: 0.082971\n",
      "Train [9600/14674 (65%)]\tLoss: 0.219556\n",
      "Train [12800/14674 (87%)]\tLoss: 0.098466\n",
      "Train set: Average loss: 0.0020, Accuracy: 14071/14674 (95.89%)\n",
      "Validation set: Average loss: 0.0263, Accuracy: 919/1756 (52.33%)\n",
      "\n",
      "Epoch:  28\n",
      "Train [0/14674 (0%)]\tLoss: 0.120686\n",
      "Train [3200/14674 (22%)]\tLoss: 0.066119\n",
      "Train [6400/14674 (43%)]\tLoss: 0.205179\n",
      "Train [9600/14674 (65%)]\tLoss: 0.123589\n",
      "Train [12800/14674 (87%)]\tLoss: 0.159880\n",
      "Train set: Average loss: 0.0020, Accuracy: 14041/14674 (95.69%)\n",
      "Validation set: Average loss: 0.0254, Accuracy: 957/1756 (54.50%)\n",
      "\n",
      "Epoch:  29\n",
      "Train [0/14674 (0%)]\tLoss: 0.128808\n",
      "Train [3200/14674 (22%)]\tLoss: 0.154224\n",
      "Train [6400/14674 (43%)]\tLoss: 0.138371\n",
      "Train [9600/14674 (65%)]\tLoss: 0.119314\n",
      "Train [12800/14674 (87%)]\tLoss: 0.102017\n",
      "Train set: Average loss: 0.0020, Accuracy: 14081/14674 (95.96%)\n",
      "Validation set: Average loss: 0.0253, Accuracy: 948/1756 (53.99%)\n",
      "\n",
      "Epoch:  30\n",
      "Train [0/14674 (0%)]\tLoss: 0.152715\n",
      "Train [3200/14674 (22%)]\tLoss: 0.090517\n",
      "Train [6400/14674 (43%)]\tLoss: 0.149566\n",
      "Train [9600/14674 (65%)]\tLoss: 0.069355\n",
      "Train [12800/14674 (87%)]\tLoss: 0.223775\n",
      "Train set: Average loss: 0.0021, Accuracy: 14017/14674 (95.52%)\n",
      "Validation set: Average loss: 0.0263, Accuracy: 950/1756 (54.10%)\n",
      "\n",
      "Epoch:  31\n",
      "Train [0/14674 (0%)]\tLoss: 0.138742\n",
      "Train [3200/14674 (22%)]\tLoss: 0.089135\n",
      "Train [6400/14674 (43%)]\tLoss: 0.162048\n",
      "Train [9600/14674 (65%)]\tLoss: 0.087168\n",
      "Train [12800/14674 (87%)]\tLoss: 0.049560\n",
      "Train set: Average loss: 0.0021, Accuracy: 14045/14674 (95.71%)\n",
      "Validation set: Average loss: 0.0254, Accuracy: 932/1756 (53.08%)\n",
      "\n",
      "Epoch:  32\n",
      "Train [0/14674 (0%)]\tLoss: 0.084485\n",
      "Train [3200/14674 (22%)]\tLoss: 0.083271\n",
      "Train [6400/14674 (43%)]\tLoss: 0.090005\n",
      "Train [9600/14674 (65%)]\tLoss: 0.111531\n",
      "Train [12800/14674 (87%)]\tLoss: 0.125656\n",
      "Train set: Average loss: 0.0021, Accuracy: 14043/14674 (95.70%)\n",
      "Validation set: Average loss: 0.0255, Accuracy: 920/1756 (52.39%)\n",
      "\n",
      "Epoch:  33\n",
      "Train [0/14674 (0%)]\tLoss: 0.098279\n",
      "Train [3200/14674 (22%)]\tLoss: 0.054753\n",
      "Train [6400/14674 (43%)]\tLoss: 0.177491\n",
      "Train [9600/14674 (65%)]\tLoss: 0.118206\n",
      "Train [12800/14674 (87%)]\tLoss: 0.155518\n",
      "Train set: Average loss: 0.0021, Accuracy: 14041/14674 (95.69%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 934/1756 (53.19%)\n",
      "\n",
      "Epoch:  34\n",
      "Train [0/14674 (0%)]\tLoss: 0.130917\n",
      "Train [3200/14674 (22%)]\tLoss: 0.157798\n",
      "Train [6400/14674 (43%)]\tLoss: 0.206655\n",
      "Train [9600/14674 (65%)]\tLoss: 0.207640\n",
      "Train [12800/14674 (87%)]\tLoss: 0.122859\n",
      "Train set: Average loss: 0.0021, Accuracy: 14038/14674 (95.67%)\n",
      "Validation set: Average loss: 0.0269, Accuracy: 899/1756 (51.20%)\n",
      "\n",
      "Epoch:  35\n",
      "Train [0/14674 (0%)]\tLoss: 0.124911\n",
      "Train [3200/14674 (22%)]\tLoss: 0.217239\n",
      "Train [6400/14674 (43%)]\tLoss: 0.155735\n",
      "Train [9600/14674 (65%)]\tLoss: 0.105698\n",
      "Train [12800/14674 (87%)]\tLoss: 0.101217\n",
      "Train set: Average loss: 0.0021, Accuracy: 14053/14674 (95.77%)\n",
      "Validation set: Average loss: 0.0263, Accuracy: 906/1756 (51.59%)\n",
      "\n",
      "Epoch:  36\n",
      "Train [0/14674 (0%)]\tLoss: 0.103930\n",
      "Train [3200/14674 (22%)]\tLoss: 0.073617\n",
      "Train [6400/14674 (43%)]\tLoss: 0.074844\n",
      "Train [9600/14674 (65%)]\tLoss: 0.090089\n",
      "Train [12800/14674 (87%)]\tLoss: 0.062702\n",
      "Train set: Average loss: 0.0021, Accuracy: 14027/14674 (95.59%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 914/1756 (52.05%)\n",
      "\n",
      "Epoch:  37\n",
      "Train [0/14674 (0%)]\tLoss: 0.118839\n",
      "Train [3200/14674 (22%)]\tLoss: 0.131559\n",
      "Train [6400/14674 (43%)]\tLoss: 0.160133\n",
      "Train [9600/14674 (65%)]\tLoss: 0.122079\n",
      "Train [12800/14674 (87%)]\tLoss: 0.118714\n",
      "Train set: Average loss: 0.0020, Accuracy: 14065/14674 (95.85%)\n",
      "Validation set: Average loss: 0.0260, Accuracy: 925/1756 (52.68%)\n",
      "\n",
      "Epoch:  38\n",
      "Train [0/14674 (0%)]\tLoss: 0.087778\n",
      "Train [3200/14674 (22%)]\tLoss: 0.221742\n",
      "Train [6400/14674 (43%)]\tLoss: 0.119481\n",
      "Train [9600/14674 (65%)]\tLoss: 0.113966\n",
      "Train [12800/14674 (87%)]\tLoss: 0.140252\n",
      "Train set: Average loss: 0.0021, Accuracy: 14043/14674 (95.70%)\n",
      "Validation set: Average loss: 0.0258, Accuracy: 940/1756 (53.53%)\n",
      "\n",
      "Epoch:  39\n",
      "Train [0/14674 (0%)]\tLoss: 0.150961\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYezGiSFctfo"
   },
   "outputs": [],
   "source": [
    "model_folder = '/scratch/sg5783/CCM_Project/model_weights/' + MODEL\n",
    "model_file = model_folder  + '/model_' + str(num_epochs) + '.pth'\n",
    "torch.save(model.state_dict(), model_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOH00Ka2QE0giBrF8e4mm92",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "CCM Project-AlexNet",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "49b4d1f0906e417e864aea18226dfea1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ca2f791e113495ca6cdc8a87fe092e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3b6000d24854c2d8d86e597c58e9e64",
      "placeholder": "",
      "style": "IPY_MODEL_987920b37ee94570a655dc244f53544f",
      "value": " 528M/528M [00:35&lt;00:00, 15.4MB/s]"
     }
    },
    "56089c3b980b47688145e2686dd0cd58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "681fbb38dd104a99905eac8b7e830fc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8478c3442abc45188fc1b1bfcb7439b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b4d1f0906e417e864aea18226dfea1",
      "max": 553433881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56089c3b980b47688145e2686dd0cd58",
      "value": 553433881
     }
    },
    "987920b37ee94570a655dc244f53544f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3b6000d24854c2d8d86e597c58e9e64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e36d104d3a824f9d99f5a134023ed3f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8478c3442abc45188fc1b1bfcb7439b0",
       "IPY_MODEL_4ca2f791e113495ca6cdc8a87fe092e5"
      ],
      "layout": "IPY_MODEL_681fbb38dd104a99905eac8b7e830fc1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
