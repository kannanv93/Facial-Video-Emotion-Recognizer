{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD, lr_scheduler\n",
    "import shutil, sys   \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy \n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model, test_loader):\n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            number_test_steps = 0\n",
    "            for batch_id, (inputs, labels) in enumerate(test_loader):\n",
    "                inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() # sum up loss of all minibatches\n",
    "                number_test_steps += 1\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data).cpu()\n",
    "                \n",
    "            \n",
    "            epoch_testloss = running_loss / number_test_steps\n",
    "            epoch_testaccuracy = running_corrects.double() / len(test_loader.dataset)\n",
    "            \n",
    "            print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            epoch_testloss, running_corrects, len(test_loader.dataset),\n",
    "            100. * epoch_testaccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on Actor wise split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to fit hardware\n",
    "\n",
    "data_dir = '/scratch/kv942/ccm_proj/datadir_act/'\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "test_loader = DataLoader(image_datasets['test'],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.4848, Accuracy: 2220/4450 (49.89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/scratch/sg5783/CCM_Project/final_folder/model_weights/actor_wise_split/alexnet_40.pth'\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 8)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "test_performance(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7952, Accuracy: 2359/4450 (53.01%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/scratch/sg5783/CCM_Project/final_folder/model_weights/actor_wise_split/VGG16_40.pth'\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 8)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "test_performance(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on Random split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to fit hardware\n",
    "\n",
    "data_dir = '/scratch/kv942/ccm_proj/datadir_rnd/'\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "test_loader = DataLoader(image_datasets['test'],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0930, Accuracy: 4693/4837 (97.02%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/scratch/sg5783/CCM_Project/final_folder/model_weights/random_data_split/alexnet_40.pth'\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 8)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "test_performance(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0739, Accuracy: 4739/4837 (97.97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/scratch/sg5783/CCM_Project/final_folder/model_weights/random_data_split/VGG16_40.pth'\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 8)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "test_performance(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
